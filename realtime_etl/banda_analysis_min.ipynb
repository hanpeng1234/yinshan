{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f8c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab3aea8b7c848f38de604eba2dcfe87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from concurrent import futures\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime,timedelta\n",
    "import pytz\n",
    "\n",
    "# print(datetime.now(pytz.timezone(\"Asia/Shanghai\")).strftime( '%Y-%m-%d'))\n",
    "today=(datetime.now()+ timedelta(-1)).strftime( '%Y-%m-%d')\n",
    "yesterday=(datetime.now(pytz.timezone(\"Asia/Shanghai\"))+ timedelta(-1)).strftime( '%Y-%m-%d')\n",
    "# ,\"banda_stream_etl\":\"1\"\n",
    "tablemap={\n",
    "    \"banda\":{\n",
    "       \n",
    "         \"t_authorized_channel1_detail\":\"\"\"      with authorized_detail as      (      SELECT  auto_loan.loan_id    ,case when w.customer_id is not null  then 'repayday'         when w.customer_id is null and detail.real_policy='payday_amount_scorecard' then 'payday'         else 'repayday' end as  acct_type        ,detail.finish_time + interval '7' hour       AS authorized_time    ,unix_timestamp(detail.finish_time)- unix_timestamp(cc.create_time)  as duration       ,detail.customer_id    ,cast(get_json_object(detail.raw_data,'$.maxAmount') AS int)/14000 AS max_authorized_amt       FROM       (       SELECT  loan_id     ,min(id) AS id       FROM `banda-etl-s3`.t_auto_review_loan   WHERE real_policy in('payday_amount_scorecard', 'repayday_amount_scorecard')   AND result = 'PASS'   AND create_time > date '2019-08-01'   GROUP BY  loan_id    )auto_loan      left jOIN  `banda-etl-s3`.t_auto_review_loan detail      ON auto_loan.id = detail.id      LEFT JOIN `banda-etl-s3`.t_loan_app cc      ON auto_loan.loan_id=cc.id      left join ( SELECT customer_id FROM `banda_analysis_etl`.t_customer_detail where is_whitelist = 'Y' ) w on detail.customer_id=w.customer_id      where detail.customer_id not IN ( select customer_id from `banda-etl-s3`.t_test_customer)      ),     withdraw_detail as     (    SELECT  loan_app_id       ,create_time + interval '7' hour AS withdraw_time    FROM `banda-etl-s3`.t_loan_app_status_log    WHERE old_status = 'AUTHORIZATION'     AND new_status = 'FINAL_REVIEW'     AND create_time > date'2019-08-01'      ),    channel1_load_detail AS     (    SELECT  *    FROM `id_adapundi_data_input`.`adapundi_channel_input_data`    WHERE create_time IN ( SELECT MAX(create_time) FROM `id_adapundi_data_input`.`adapundi_channel_input_data` where  substr(create_time,1,1)='2'   )     )     SELECT  aa.*       ,CASE WHEN cc.channel1 is not null THEN cc.channel1  ELSE 'Others' END AS channel      ,dd.withdraw_time      ,now() as insert_time    FROM authorized_detail aa    LEFT JOIN     (   SELECT  customer_id      ,coalesce(media_source,'None') AS media_source      ,coalesce(agency,'None') AS agency   FROM `banda-etl-s3`.t_customer_install_info     ) bb    ON aa.customer_id=bb.customer_id    LEFT JOIN channel1_load_detail cc    ON bb.media_source = cc.mediasource AND bb.agency = cc.agency     LEFT JOIN withdraw_detail dd    ON aa.loan_id = dd.loan_app_id \"\"\"  ,\n",
    "         \"\":\"\"\n",
    "    }\n",
    "   \n",
    "}\n",
    "def make_col_temptable(tableType,tableNm):\n",
    "    sql=tablemap[tableType][tableNm]\n",
    "    tablepath=\"s3://rupiahplus-data-warehouse/etl/\"+tableType+\"/analysis/\"+tableNm\n",
    "    spark.sql(sql).write.mode(\"overwrite\").orc(tablepath)\n",
    "#     builtins\n",
    "# \n",
    "if __name__ == \"builtins\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Python Demo\")\\\n",
    "        .config(\"hive.metastore.client.factory.class\", \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "#     spark.conf.set(\"spark.scheduler.mode\",\"FAIR\")\n",
    "    spark.conf.set(\"spark.sql.shuffle.partitions\",20)\n",
    "    for tableType in tablemap:\n",
    "#         databasesql=\"show tables in \"+databaseName\n",
    "#         tables=spark.sql(databasesql)\n",
    "#         tablelist=tables.collect();\n",
    "        executor=None\n",
    "        with futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures_result=futures.wait([executor.submit(make_col_temptable,tableType, tableNm) for tableNm in tablemap[tableType]])\n",
    "            for  future in futures_result[0]:\n",
    "                print(future.result())\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98a70dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9770a7d8d83943dfb06a9fe9d23bcd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1628841417076_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-3-0-22.ap-southeast-1.compute.internal:20888/proxy/application_1628841417076_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-3-0-77.ap-southeast-1.compute.internal:8042/node/containerlogs/container_1628841417076_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+------------------------------+------------------+----------------+---------------------------+-----------------------------+--------------------+------------+---------------+----------------------+-----------------------+--------------------+--------------------+\n",
      "|loan_app_id|final_assign_ingroup_collector_id|final_assign_ingroup_collector|overduedays_assign|        loan_amt|fst_assign_ingroup_time_ind|final_assign_ingroup_time_ind|   paid_off_time_ind|assign_stage|        trigger|paid_amt_before_assign|paid_prin_before_assign|assign_unpaid_amount|         insert_time|\n",
      "+-----------+---------------------------------+------------------------------+------------------+----------------+---------------------------+-----------------------------+--------------------+------------+---------------+----------------------+-----------------------+--------------------+--------------------+\n",
      "|    9591018|                           102103|               Benny fahdiyani|                 1| 700000.00000000|       2021-01-07 05:00:...|         2021-01-07 05:00:...|2021-01-07 14:16:...|        Q1_A|OVERDUE_1_DAY_A|       770000.00000000|        602000.00000000|      98000.00000000|2021-08-13 08:13:...|\n",
      "|    9581634|                           102096|            Achmad widodo - Q2|                 1|1600000.00000000|       2021-01-09 05:00:...|         2021-01-09 05:00:...|2021-01-09 09:02:...|        Q1_A|OVERDUE_1_DAY_A|      1930000.00000000|       1546000.00000000|      54000.00000000|2021-08-13 08:13:...|\n",
      "|    9612734|                           102078|          Muhamad Chairul A...|                 1|2700000.00000000|       2021-01-10 05:00:...|         2021-01-10 05:00:...|2021-01-10 14:58:...|        Q1_A|OVERDUE_1_DAY_A|      2488000.00000000|       1840000.00000000|     860000.00000000|2021-08-13 08:13:...|\n",
      "|    9617680|                           102096|            Achmad widodo - Q2|                 1|1600000.00000000|       2021-01-11 05:00:...|         2021-01-11 05:00:...|2021-01-16 18:20:...|        Q1_A|OVERDUE_1_DAY_A|       500000.00000000|        116000.00000000|    1484000.00000000|2021-08-13 08:13:...|\n",
      "|    9724981|                           102096|            Achmad widodo - Q2|                 1|3300000.00000000|       2021-01-12 05:00:...|         2021-01-12 05:00:...|2021-01-12 06:28:...|        Q1_A|OVERDUE_1_DAY_A|      2100000.00000000|       1555600.00000000|    1744400.00000000|2021-08-13 08:13:...|\n",
      "|    9796124|                           102096|            Achmad widodo - Q2|                 1|1420000.00000000|       2021-01-20 05:00:...|         2021-01-20 05:00:...|2021-01-20 18:52:...|        Q1_A|OVERDUE_1_DAY_A|       658000.00000000|        419440.00000000|    1000560.00000000|2021-08-13 08:13:...|\n",
      "|    9709768|                           102103|               Benny fahdiyani|                 1|2600000.00000000|       2021-01-20 05:00:...|         2021-01-20 05:00:...|2021-01-20 14:26:...|        Q1_A|OVERDUE_1_DAY_A|      2100000.00000000|       1476000.00000000|    1124000.00000000|2021-08-13 08:13:...|\n",
      "|   10045855|                           102078|          Muhamad Chairul A...|                 1|1200000.00000000|       2021-02-21 06:00:...|         2021-02-21 06:00:...|2021-02-26 17:34:...|        Q1_A|OVERDUE_1_DAY_A|      1200000.00000000|        912000.00000000|     288000.00000000|2021-08-13 08:13:...|\n",
      "|    9750375|                           102103|               Benny fahdiyani|                 1|3800000.00000000|       2021-01-26 05:00:...|         2021-01-26 05:00:...|2021-01-26 10:06:...|        Q1_A|OVERDUE_1_DAY_A|      2412000.00000000|       1500000.00000000|    2300000.00000000|2021-08-13 08:13:...|\n",
      "|    9786737|                           102078|          Muhamad Chairul A...|                 1|1750000.00000000|       2021-01-28 05:00:...|         2021-01-28 05:00:...|2021-01-30 01:38:...|        Q1_A|OVERDUE_1_DAY_A|      1660000.00000000|       1240000.00000000|     510000.00000000|2021-08-13 08:13:...|\n",
      "|    9793120|                           102096|            Achmad widodo - Q2|                 1| 900000.00000000|       2021-01-29 05:00:...|         2021-01-29 05:00:...|2021-01-29 09:46:...|        Q1_A|OVERDUE_1_DAY_A|      1070705.00000000|        854705.00000000|      45295.00000000|2021-08-13 08:13:...|\n",
      "|    9880502|                           102096|            Achmad widodo - Q2|                 1|2990000.00000000|       2021-02-06 06:00:...|         2021-02-06 06:00:...|2021-02-06 12:38:...|        Q1_A|OVERDUE_1_DAY_A|      2407600.00000000|       1690000.00000000|    1300000.00000000|2021-08-13 08:13:...|\n",
      "|    9898787|                           102176|                  Adi Triyanto|                 1|2200000.00000000|       2021-02-08 05:00:...|         2021-02-08 05:00:...|2021-02-10 11:04:...|        Q1_A|OVERDUE_1_DAY_A|       150000.00000000|                   0E-8|    2200000.00000000|2021-08-13 08:13:...|\n",
      "|   10003853|                           102176|                  Adi Triyanto|                 1|3000000.00000000|       2021-02-09 06:00:...|         2021-02-09 06:00:...|2021-02-09 06:10:...|        Q1_A|OVERDUE_1_DAY_A|      2850000.00000000|       2346000.00000000|     654000.00000000|2021-08-13 08:13:...|\n",
      "|    9921637|                           102096|            Achmad widodo - Q2|                 1| 800000.00000000|       2021-02-10 06:00:...|         2021-02-10 06:00:...|2021-02-10 21:38:...|        Q1_A|OVERDUE_1_DAY_A|       100000.00000000|                   0E-8|     800000.00000000|2021-08-13 08:13:...|\n",
      "|   10069526|                           102096|            Achmad widodo - Q2|                 1| 920000.00000000|       2021-02-23 06:00:...|         2021-02-23 06:00:...|2021-02-24 15:44:...|        Q1_A|OVERDUE_1_DAY_A|       102491.00000000|                   0E-8|     920000.00000000|2021-08-13 08:13:...|\n",
      "|   10064254|                           102163|          Srinenda silalahi...|                 1| 520000.00000000|       2021-02-23 06:00:...|         2021-02-23 06:00:...|2021-02-23 20:44:...|        Q1_A|OVERDUE_1_DAY_A|       644000.00000000|        519200.00000000|        800.00000000|2021-08-13 08:13:...|\n",
      "|   10101948|                           102078|          Muhamad Chairul A...|                 1|4200000.00000000|       2021-02-25 05:00:...|         2021-02-25 05:00:...|2021-02-25 08:58:...|        Q1_A|OVERDUE_1_DAY_A|      2000000.00000000|        992000.00000000|    3208000.00000000|2021-08-13 08:13:...|\n",
      "|   10084590|                           102078|          Muhamad Chairul A...|                 1|4800000.00000000|       2021-02-26 05:00:...|         2021-02-26 05:00:...|2021-03-01 14:16:...|        Q1_A|OVERDUE_1_DAY_A|      1352000.00000000|        200000.00000000|    4600000.00000000|2021-08-13 08:13:...|\n",
      "|   10128198|                           102096|            Achmad widodo - Q2|                 1|1400000.00000000|       2021-02-28 06:00:...|         2021-02-28 06:00:...|2021-02-28 22:10:...|        Q1_A|OVERDUE_1_DAY_A|      1000000.00000000|        664000.00000000|     736000.00000000|2021-08-13 08:13:...|\n",
      "+-----------+---------------------------------+------------------------------+------------------+----------------+---------------------------+-----------------------------+--------------------+------------+---------------+----------------------+-----------------------+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "-- 记录每个案件每次分案的信息\n",
    "-- 一个案件在一个队列内部流转，对于队列来说计算最早那次流入算作流入队列时间，但是对于催收员来说，仅计算最后一次队列内流转的分案信息\n",
    "-- 需要剔除分案之前结清的订单\n",
    "-- 月初流转的数据怎么计算：月初流转以后进行判断，如果可以流转到下个队列就流转（fst_assign_ingroup_time），如果不可以，就停留在当前队列（final_assign_ingroup_time）\n",
    "with paid_off_detail as \n",
    "(\n",
    "SELECT  lg.loan_app_id\n",
    "       ,lg.create_time AS paid_off_time\n",
    "FROM `banda-etl-s3`.t_loan_app app2\n",
    "JOIN `banda-etl-s3`.t_loan_app_status_log lg\n",
    "ON lg.loan_app_id=app2.id AND lg.new_status='PAID_OFF'\n",
    "WHERE app2.product_name='RUPIAHONE'\n",
    "AND app2.status IN ('CURRENT', 'GRACE_PERIOD', 'OVERDUE', 'PAID_OFF')  \n",
    "),\n",
    "assign_detail as \n",
    "(\n",
    "\tselect*from\n",
    "\t(\n",
    "\tSELECT  new_assign.*\n",
    "\t\t   ,row_number()OVER (PARTITION BY ref_id,date(create_time+interval'7'hour) ORDER BY create_time DESC )AS rn\n",
    "\t\t   ,paid_off.paid_off_time --结清时间（分案之后的）\n",
    "\tFROM `banda-etl-s3`.t_case_distribution_log new_assign\n",
    "\tleft join paid_off_detail paid_off on  new_assign.ref_id=paid_off.loan_app_id\n",
    "\tWHERE topic='AVERAGE_ASSIGN_CASE_TO_REVIEWER'\n",
    "\tand  (create_time<paid_off_time or  paid_off.loan_app_id is null)--剔除分案之前已结清分案\n",
    "\t) \n",
    "\twhere rn=1 --月初可能出现一天内分案两次的情况，取最后一次为准\n",
    "),\n",
    "audit_final as\n",
    "(\n",
    "\tselect*from \n",
    "\t(\n",
    "\tSELECT  ref_id                                           AS loan_app_id\n",
    "\t       ,reviewer_id                                      AS collector_id\n",
    "\t       ,trigger\n",
    "\t\t   ,create_time as final_assign_ingroup_time -- 组内最后一次分案时间(当月)\n",
    "\t\t   ,month(create_time+interval'7'hour) as assign_month\n",
    "\t\t   ,paid_off_time\n",
    "\t\t   ,row_number()OVER (PARTITION BY ref_id,trigger,month(create_time+interval'7'hour) ORDER BY create_time DESC )AS rn\n",
    "\tFROM assign_detail\n",
    "\t)\n",
    "\twhere rn=1\n",
    "),\n",
    "audit_fst as \n",
    "(\tselect \n",
    "    ref_id\n",
    "\t,trigger\n",
    "\t,month(create_time+interval'7'hour) as assign_month\n",
    "\t,min(create_time) as fst_assign_ingroup_time  -- 首次进入组内分案时间\n",
    "    FROM assign_detail\n",
    "\tgroup by \n",
    "\tref_id\n",
    "\t,trigger\n",
    "\t,month(create_time+interval'7'hour)\n",
    "), \n",
    "audit_detail as \n",
    "(\n",
    "select\n",
    "a.*,b.fst_assign_ingroup_time\n",
    "from audit_final a \n",
    "left join audit_fst b on a.loan_app_id=b.ref_id and a.trigger=b.trigger and a.assign_month=b.assign_month\n",
    "),\n",
    "assign_detail_nosold as -- 剔除分案并且被出售记录\n",
    "(\n",
    "\tSELECT  t1.loan_app_id\n",
    "\t       ,t1.collector_id as final_assign_ingroup_collector_id\n",
    "\t       ,t1.full_name_x  as final_assign_ingroup_collector\n",
    "\t       ,trigger\n",
    "\t       ,t1.amount\n",
    "\t       ,t1.fst_assign_ingroup_time\n",
    "\t       ,t1.final_assign_ingroup_time\n",
    "\t       ,t1.overdue_assign\n",
    "\t       ,t1.id\n",
    "\t       ,t1.erase_amount\n",
    "\t\t   ,t1.paid_off_time\n",
    "\tFROM\n",
    "\t(\n",
    "\t\tSELECT  audit.loan_app_id\n",
    "\t\t       ,audit.collector_id                                                                                       \n",
    "\t\t       ,ad.full_name_x                                                                                           \n",
    "\t\t       ,audit.fst_assign_ingroup_time\n",
    "\t\t       ,audit.final_assign_ingroup_time\n",
    "\t\t\t   ,audit.paid_off_time\n",
    "\t\t       ,app.amount\n",
    "\t\t       ,lpay.due_date\n",
    "\t\t       ,lpay.id\n",
    "\t\t       ,lpay.erase_amount\n",
    "\t\t       ,trigger\n",
    "\t\t       ,datediff(DATE(audit.fst_assign_ingroup_time+interval'7'hour),DATE(lpay.due_date+interval'7'hour)) AS overdue_assign --分案时逾期天数\n",
    "\t\tFROM audit_detail audit \n",
    "\t\tLEFT JOIN`banda-etl-s3`.t_admin ad\n",
    "\t\tON ad.id=audit.collector_id\n",
    "\t\tLEFT JOIN `banda-etl-s3`.t_loan_app app\n",
    "\t\tON app.id=audit.loan_app_id\n",
    "\t\tLEFT JOIN `banda-etl-s3`.t_lpay lpay\n",
    "\t\tON lpay.loan_app_id=audit.loan_app_id\n",
    "\t\tLEFT JOIN\n",
    "\t\t(\n",
    "\t\t\tSELECT  rel.loan_id\n",
    "\t\t\tFROM `banda-etl-s3`.t_loan_tag_rel rel\n",
    "\t\t\tWHERE rel.tag_id IN ( SELECT id FROM `banda-etl-s3`.t_tag WHERE type='SELLING_CASE' )\n",
    "\t\t\tAND rel.status='ACTIVE' \n",
    "\t\t) mba\n",
    "\t\tON mba.loan_id=audit.loan_app_id\n",
    "\t\tLEFT JOIN `banda-etl-s3`.t_collection_blacklist blacklist\n",
    "\t\tON blacklist.customer_id=app.customer_id AND blacklist.status='ACTIVE'\n",
    "\t\tWHERE blacklist.customer_id IS NULL\n",
    "\t\tAND mba.loan_id IS NULL -- 出售资产 \n",
    "\t)t1\n",
    ")\n",
    "\n",
    "-- 建立分案信息明细表 日全量刷新  t_distribute_detail_daily\n",
    "SELECT  t3.*\n",
    "       ,CASE WHEN t3.paid_prin_before_assign IS NULL THEN t3.loan_amt  ELSE t3.loan_amt-t3.paid_prin_before_assign END AS assign_unpaid_amount -- 剔除在分案之前已还款的金额\n",
    "\t   ,now() as insert_time\n",
    "FROM\n",
    "(\n",
    "\tSELECT  t2.loan_app_id\n",
    "\t       ,t2.final_assign_ingroup_collector_id\n",
    "\t       ,t2.final_assign_ingroup_collector\n",
    "\t       ,t2.overdue_assign                            AS overduedays_assign\n",
    "\t       ,t2.amount                                    AS loan_amt\n",
    "\t       ,t2.fst_assign_ingroup_time+interval'7'hour   AS fst_assign_ingroup_time_ind\n",
    "\t       ,t2.final_assign_ingroup_time+interval'7'hour AS final_assign_ingroup_time_ind\n",
    "\t       ,t2.paid_off_time+interval'7'hour             AS paid_off_time_ind\n",
    "\t       ,if(map_load.enum is not null,map_load.map,trigger_group.description) as assign_stage\n",
    "\t       ,t2.trigger\n",
    "\t       ,SUM(deposit.cleared_amount)                  AS paid_amt_before_assign\n",
    "\t       ,SUM(clear.principal)                         AS paid_prin_before_assign\n",
    "\tFROM assign_detail_nosold t2\n",
    "\tLEFT JOIN `banda-etl-s3`.t_lpay_deposit deposit\n",
    "\tON deposit.lpay_id=t2.id AND deposit.status='CLEARED' AND deposit.create_time<t2.fst_assign_ingroup_time \n",
    "\tAND ( deposit.deposit_method !='DIRECT_TRANSFER' OR (deposit.deposit_method ='DIRECT_TRANSFER' AND deposit.cleared_amount !=ceil(t2.erase_amount)))\n",
    "\tLEFT JOIN `banda-etl-s3`.t_reduce reduce\n",
    "\tON reduce.deposit_id =deposit.id AND reduce.reduce_status='SUCCEED'\n",
    "\tLEFT JOIN `banda-etl-s3`.t_clear_detail_log clear\n",
    "\tON clear.deposit_id=deposit.id\n",
    "\tLEFT JOIN (select*from zhusu.enum_mapping_load_table where id='1001') map_load  on t2.trigger=map_load.enum\n",
    "    LEFT JOIN\n",
    "\t(select*from (\n",
    "\t\tSELECT  trigger\n",
    "\t\t       ,description\n",
    "\t\t       ,row_number()over(partition by trigger ORDER BY update_time desc)rn\n",
    "\t\tFROM `banda-etl-s3`.t_trigger_group )\n",
    "\t\tWHERE rn=1 \n",
    "\t) trigger_group\n",
    "\tON t2.trigger=trigger_group.trigger\n",
    "\tWHERE (reduce.reduce_type IS NULL OR reduce.reduce_type NOT IN ('DELAY_CALLBACK', 'NONE_CALLBACK_REDUCE', 'COLLECTION_REDUCE'))\n",
    "\tGROUP BY  t2.loan_app_id\n",
    "\t         ,t2.final_assign_ingroup_collector_id\n",
    "\t         ,t2.final_assign_ingroup_collector\n",
    "\t         ,t2.overdue_assign\n",
    "\t         ,t2.amount\n",
    "\t         ,t2.fst_assign_ingroup_time+interval'7'hour\n",
    "\t         ,t2.final_assign_ingroup_time+interval'7'hour\n",
    "\t         ,t2.paid_off_time+interval'7'hour\n",
    "\t         ,if(map_load.enum is not null,map_load.map,trigger_group.description)\n",
    "\t         ,t2.trigger\n",
    ")t3\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
