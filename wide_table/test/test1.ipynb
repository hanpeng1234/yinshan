{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a09a49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf472f9082b47f8af5d81a35005b838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql1.sql\n",
      "sql1\n",
      "+--------------+----------------+\n",
      "|sql1_usercount|sql1_create_time|\n",
      "+--------------+----------------+\n",
      "|          2270|      2021-05-08|\n",
      "|          6244|      2021-05-07|\n",
      "|          5532|      2021-05-06|\n",
      "|          5207|      2021-05-05|\n",
      "|          5632|      2021-05-04|\n",
      "|          7269|      2021-05-03|\n",
      "|          6517|      2021-05-02|\n",
      "|          7507|      2021-05-01|\n",
      "|          6859|      2021-04-30|\n",
      "|          8956|      2021-04-29|\n",
      "|          6901|      2021-04-28|\n",
      "|          8371|      2021-04-27|\n",
      "|          8747|      2021-04-26|\n",
      "|          6549|      2021-04-25|\n",
      "|          7402|      2021-04-24|\n",
      "|          7886|      2021-04-23|\n",
      "|          7774|      2021-04-22|\n",
      "|          7230|      2021-04-21|\n",
      "|          7570|      2021-04-20|\n",
      "|          7403|      2021-04-19|\n",
      "+--------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "sql2.sql\n",
      "sql2\n",
      "+---------------+----------------+\n",
      "|sql2_issuecount|sql2_create_time|\n",
      "+---------------+----------------+\n",
      "|           2162|      2021-05-08|\n",
      "|           4824|      2021-05-07|\n",
      "|           5049|      2021-05-06|\n",
      "|           5395|      2021-05-05|\n",
      "|           5943|      2021-05-04|\n",
      "|           6869|      2021-05-03|\n",
      "|           5083|      2021-05-02|\n",
      "|           5762|      2021-05-01|\n",
      "|           6261|      2021-04-30|\n",
      "|           5466|      2021-04-29|\n",
      "|           5389|      2021-04-28|\n",
      "|           5492|      2021-04-27|\n",
      "|           5356|      2021-04-26|\n",
      "|           4655|      2021-04-25|\n",
      "|           4898|      2021-04-24|\n",
      "|           5260|      2021-04-23|\n",
      "|           4554|      2021-04-22|\n",
      "|           4349|      2021-04-21|\n",
      "|           4857|      2021-04-20|\n",
      "|           4838|      2021-04-19|\n",
      "+---------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "import pkgutil\n",
    "start = date(2019, 8, 1)\n",
    "end = date.today()\n",
    "delta = end - start\n",
    "dates = [start + timedelta(days=d) for d in range(delta.days + 1)]\n",
    "idx = spark.createDataFrame(dates, \"date\").toDF(\"date\")\n",
    "# idx.show()\n",
    "base_name = 'sql/'\n",
    "legacy_sql_names = {\n",
    "    'sql1.sql':\"\"\"SELECT count(tmp.id) usercount,tmp.create_time\n",
    "                    FROM \n",
    "                        (SELECT date_format(create_time,'yyyy-MM-dd')as create_time, id\n",
    "                        FROM `banda-etl-s3`.t_customer ) tmp   \n",
    "                    GROUP BY  tmp.create_time\n",
    "                    having tmp.create_time>  '2021-01-01'\n",
    "                    order by tmp.create_time desc\"\"\",\n",
    "    'sql2.sql':\"\"\"SELECT count(tmp.id) issuecount,tmp.create_time\n",
    "                    FROM \n",
    "                        (SELECT date_format(create_time,'yyyy-MM-dd')as create_time, id\n",
    "                        FROM `banda-etl-s3`.t_loan_issue  ) tmp\n",
    "                    GROUP BY  tmp.create_time\n",
    "                    having tmp.create_time>  '2020-12-01'\n",
    "                    order by tmp.create_time desc\"\"\",\n",
    "}\n",
    "for name in  legacy_sql_names:\n",
    "    print(name)\n",
    "    prefix = name[:name.index('.')]\n",
    "    print(prefix)\n",
    "    df = spark.sql(legacy_sql_names[name])\n",
    "    for c in df.columns:\n",
    "        if c != 'date':\n",
    "            df = df.withColumnRenamed(c, prefix+'_'+c)\n",
    "    df.show()\n",
    "# for name in legacy_sql_names:\n",
    "# .decode(\"utf-8\")\n",
    "# print('/wide_table/test/'+base_name + 'sql1.sql')\n",
    "# txt = pkgutil.get_data(\n",
    "#     'work.wide_table.test', base_name + 'sql1.sql')\n",
    "# print(txt)\n",
    "# df = spark.sql(txt)\n",
    "# prefix = name[:name.index('.')]\n",
    "# for c in df.columns:\n",
    "#     if c != 'date':\n",
    "#         df = df.withColumnRenamed(c, prefix+'_'+c)\n",
    "# legacy_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929ae7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3ef9de5055427dba7639053dfb134a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***获取当前目录***\n",
      "/"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('***获取当前目录***')\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
