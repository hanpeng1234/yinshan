{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74b68998d3c40ae8634d8b288db4025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1601261032657_0004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-15-241.ap-southeast-1.compute.internal:20888/proxy/application_1601261032657_0004/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-9-227.ap-southeast-1.compute.internal:8042/node/containerlogs/container_1601261032657_0004_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No module named 'pandas'\n",
      "Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'pandas'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import json as js\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "from pyathena import connect\n",
    "import pandas as pd\n",
    "conn = connect(s3_staging_dir='s3://aws-athena-query-results-ap-southeast-1-855696220043',\n",
    "               region_name='ap-southeast-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timedelta\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pytz\n",
    "\n",
    "# print()builtins\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Demo\") \\\n",
    "        .config(\"hive.metastore.client.factory.class\",\n",
    "                \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\") \\\n",
    "        .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "    spark.conf.set(\"hive.exec.dynamic.partition.mode\", \"nonstrict\");\n",
    "    spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "    hirdparty_t_task=spark.sql(\"\"\"\n",
    "    select \n",
    "    id,\n",
    "    customer_id,\n",
    "    loan_id,\n",
    "    channel,\n",
    "    channel_id,\n",
    "    thirdparty_id,\n",
    "    status,\n",
    "    retry_times,\n",
    "    response,\n",
    "    cast(create_time as string) as create_time,\n",
    "    cast(update_time as string) as update_time,\n",
    "    client_id,\n",
    "    cast(query_key as string) as query_key,\n",
    "    year(to_date(a.create_time)) as year,\n",
    "    if(length(MONTH(to_date(a.create_time)))=1,concat(\"0\",MONTH(to_date(a.create_time))),MONTH(to_date(a.create_time))) as month,\n",
    "    if(length(day(to_date(a.create_time)))=1,concat(\"0\",day(to_date(a.create_time))),day(to_date(a.create_time))) as day\n",
    "    from `lovina_etl_s3`.`t_task_1`a\n",
    "    where id < 44982821  \n",
    "    and  status=40\n",
    "    and channel != 440\n",
    "    \"\"\")\n",
    "    thirdparty_t_task.write.mode(\"append\").partitionBy(\"year\",\"month\",\"day\").orc(\"s3://rupiahplus-data-warehouse/stream/thirdparty/thirdparty_t_task/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38604aac0ab940d3a473fc3998d6a356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"airflow_cmd\":\"airflow pause airflowParamsCron\",\"arguments\":{},\"call_time\":\"Tue, 12 Jan 2021 07:28:58 GMT\",\"http_response_code\":200,\"output\":{\"stderr\":\"\",\"stdin\":\"\",\"stdout\":\"Dag: airflowParamsCron, paused: True\\n\"},\"post_arguments\":{\"api\":\"pause\",\"dag_id\":\"airflowParamsCron\"},\"response_time\":\"Tue, 12 Jan 2021 07:35:19 GMT\",\"status\":\"OK\"}\n",
      "\n",
      "{'airflow_cmd': 'airflow pause airflowParamsCron', 'arguments': {}, 'call_time': 'Tue, 12 Jan 2021 07:28:58 GMT', 'http_response_code': 200, 'output': {'stderr': '', 'stdin': '', 'stdout': 'Dag: airflowParamsCron, paused: True\\n'}, 'post_arguments': {'api': 'pause', 'dag_id': 'airflowParamsCron'}, 'response_time': 'Tue, 12 Jan 2021 07:35:19 GMT', 'status': 'OK'}"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import urllib.request\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Python Demo\")\\\n",
    "        .config(\"hive.metastore.client.factory.class\", \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\") \\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "# restUri = \"http://ec2-18-141-168-52.ap-southeast-1.compute.amazonaws.com:8080/admin/rest_api/api\";\n",
    "if __name__ == \"__main__\":\n",
    "    restUri= 'http://ec2-18-141-168-52.ap-southeast-1.compute.amazonaws.com:8080/admin/rest_api/api'\n",
    "    PostParam = \"#PostParam#\"\n",
    "    PostParam = \"api=pause&dag_id=airflowParamsCron\"\n",
    "    DATA = PostParam.encode('utf8')\n",
    "    req = urllib.request.Request(url = restUri, data=DATA, method='GET')\n",
    "    req.add_header('Content-type', 'application/x-www-form-urlencoded')\n",
    "    r = urllib.request.urlopen(req).read()\n",
    "    print(r.decode('utf8'))\n",
    "    org_obj = json.loads(r.decode('utf8'))\n",
    "    print(org_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2269e2036659428abb7a1c15d3d057e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method RDD.getNumPartitions of ParallelCollectionRDD[90] at parallelize at PythonRDD.scala:195>\n",
      "[('l', 8), ('y', 2), ('', 24), ('i', 2), ('s', 1), ('c', 1), ('e', 8), ('m', 3), ('a', 3), ('h', 6), ('.', 1), ('o', 6), (',', 2), ('n', 4), ('t', 2), ('u', 1)]"
     ]
    }
   ],
   "source": [
    "def def1(f1,f2):\n",
    "    return f1*f2\n",
    "def def2(f3,f4):\n",
    "    return f3+f4\n",
    "rdd1=sc.parallelize([1,2,3,4,5,6,7],2)\n",
    "rdd0=sc.parallelize(({\"a\",1},{\"b\",2},{\"a\",3}),2)\n",
    "print(rdd1.getNumPartitions)\n",
    "rdd2=rdd1.aggregate(10,def1,def2)\n",
    "# rdd2=rdd1.reduce(lambda x, y:  x+y)\n",
    "# rdd2=rdd1.reduce(lambda x, y:  x+y)\n",
    "# rdd3=rdd0.reduceByKey(lambda x,y:x+y )\n",
    "# print(rdd2)\n",
    "# print(rdd3.collectAsMap())\n",
    "words=sc.parallelize(\"hello,my name is han , nice to meet you. hello hello hello han\").flatMap(lambda x :x.split(' ')).map(lambda x:(x,1)).reduceByKey(lambda x,y:(x+y))\n",
    "print(words.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937f135923f4475abb16ebf11c86af5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builtins\n",
      "<function hmac_sha256 at 0x7f46b2f954d0>\n",
      "banda_stream_etl\n",
      "t_admin etldate, etlindex, id, mobile, password, full_name, type, status, failed_login_count, create_time, update_time, call_center_id_3cx, team_leader_id, password_salt, entry_time, token, auto_call_id_yixun, password_set_time, account_id\n",
      "t_admin_audit etldate, etlindex, id, admin_id, access_mode, topic, subject, loan_app_id, param_l, param_h, comment, create_time, ip\n",
      "t_admin_group etldate, etlindex, id, admin_id, group_id, status, update_id, create_time, update_time, weight, virtual_count\n",
      "t_admin_group_rel etldate, etlindex, admin_id, group_id, id\n",
      "t_af_bill etldate, etlindex, id, event_name, media_source, agency, campaign, count, ifnull(total_cost,0) as total_cost, start_date, end_date, ifnull(price,0) as price, create_time\n",
      "t_amount_reduce_record etldate, etlindex, id, customer_id, loan_app_id, ifnull(repayment_amount,0) as repayment_amount, ifnull(reduce_amount,0) as reduce_amount, status, type, operation_id, approver_id, material, remark, refuse_reason, create_time, update_time, approver_time, refund_status, deposit_id\n",
      "t_ai_rudder_schedule_mobile etldate, etlindex, id, mobile, schedule_name, schedule_id, status, create_time, update_time, hangup_type, call_start, call_end, call_times, call_status, call_id, intention, ring_type\n",
      "t_auto_review_loan etldate, etlindex, id, riskengine_id, customer_id, loan_id, name, ktp, mobile, success, error_message, result, reject_message, create_time, finish_time, duration, real_policy, switch_manual_reason, raw_data\n",
      "t_bankcard_merchant etldate, etlindex, id, merchant_code, status, limit_num, white_list_ip, secret_key, callback_url, remark, create_time, update_time\n",
      "t_bankcard etldate, etlindex, id, customer_id, loan_app_id, card_no, bank_code, province, city, branch, verify_account_holder_name, verify_status, create_time, update_time, holder_name, validation_id\n",
      "t_bankcard_verify etldate, etlindex, id, merchant_id, card_no, bank_code, swift_code, holder_name, verify_channel, verify_status, verify_account_holder_name, validation_id, fail_reason, remark, create_time, update_time\n",
      "t_contact etldate, etlindex, id, customer_id, loan_app_id, name, mobile, relation, credential_no, credential_type, address, company_name, job_title, create_time, update_time, comment, mobile_status, contact_status, status\n",
      "t_coupon_request etldate, etlindex, id, customer_id, loan_id, ifnull(coupon_amount,0) as coupon_amount, code, status, type, start_date, end_date, create_time, update_time\n",
      "t_collection_blacklist etldate, etlindex, id, admin_id, customer_id, status, create_time, update_time, comment\n",
      "t_collection_audit etldate, etlindex, id, admin_id, collector_id, access_mode, topic, subject, loan_app_id, group_name, param, comment, create_time, ip\n",
      "t_code etldate, etlindex, id, trigger, send_to, send_type, send_channel, code, status, create_time, update_time, failed_count\n",
      "t_clear_detail_log etldate, etlindex, id, loan_id, lpay_id, deposit_id, lpay_status_before, lpay_status_after, ifnull(principal,0) as principal, ifnull(service_fee,0) as service_fee, ifnull(interest,0) as interest, ifnull(penalty,0) as penalty, ifnull(rollover,0) as rollover, ifnull(total,0) as total, deposit_disburse, create_time, ifnull(default_fee,0) as default_fee, ifnull(rollover_principal_fee,0) as rollover_principal_fee, loan_app_status, due_date, ifnull(principal_accr,0) as principal_accr, ifnull(principal_paid,0) as principal_paid, ifnull(interest_accr,0) as interest_accr, ifnull(interest_paid,0) as interest_paid, ifnull(default_accr,0) as default_accr, ifnull(default_paid,0) as default_paid, ifnull(rollover_fee_accr,0) as rollover_fee_accr, ifnull(rollover_fee_paid,0) as rollover_fee_paid, ifnull(default_fee_accr,0) as default_fee_accr, ifnull(default_fee_paid,0) as default_fee_paid, deposit_type\n",
      "t_channel_details etldate, etlindex, id, channel_key, af_channel, media_source, event_name, body, ip_address, create_time, fb_campaign_name, campaign, agency, fb_campaign_id, ga_id\n",
      "t_case_distribution_log etldate, etlindex, id, admin_id, ref_id, reviewer_id, trigger, topic, subject, comment, group_id, create_time\n",
      "t_coupon_send etldate, etlindex, id, customer_id, ifnull(coupon_amount,0) as coupon_amount, structure, send_trigger, coupon_type, start_date, end_date, create_time, status\n",
      "t_customer etldate, etlindex, id, uid, mobile, email, password, invite_code, status, status_expired_time, last_login_time, failed_login_count, create_time, update_time, channel_key, imei, ifnull(rated_interest_rate,0) as rated_interest_rate, inviter_id, rank, mobile_status, type, main_account\n",
      "t_deposit_callback_log etldate, etlindex, id, customer_id, deposit_channel, deposit_method, payment_code, ifnull(amount,0) as amount, request_msg, create_time, update_time, status, transaction_id\n",
      "t_employment etldate, etlindex, id, customer_id, loan_app_id, company_name, company_type, company_phone, company_size, company_province, company_city, company_district, company_area, company_address, company_establish_time, work_province, work_city, work_district, work_area, work_address, profession, title, salary, work_email, work_start_from, create_time, update_time, salary_day\n",
      "t_department_group etldate, etlindex, id, name, description, parent_id, path, is_end, status, type, create_time, update_time\n",
      "t_customer_tag_rel etldate, etlindex, id, customer_id, tag_id, status, create_time, update_id, update_time, comment\n",
      "t_customer_install_info etldate, etlindex, id, customer_id, channel_key, ga_id, imei, channel_details_id, event_name, af_channel, media_source, campaign, agency, fb_campaign_id, fb_campaign_name, download_time, install_time, create_time, android_id\n",
      "t_customer_device_info etldate, etlindex, id, customer_id, type, value, create_time, comment\n",
      "t_customer_app etldate, etlindex, id, customer_id, customer_device_info_id, channel_details_id, event_name, af_channel, media_source, download_time, install_time, create_time\n",
      "t_engine_rule_detail etldate, etlindex, id, loan_id, code, value, result, rule_name, description, auto_review_loan_id, create_time\n",
      "t_loan_app_status_log etldate, etlindex, id, loan_app_id, operator_id, old_status, new_status, create_time\n",
      "t_file etldate, etlindex, id, customer_id, loan_app_id, file_type, file_kind, path, metadata, create_time, update_time\n",
      "t_loan_app_review_summary etldate, etlindex, id, loan_app_id, reviewing_loans_status, repaying_loans_status, rejected_loans_status, in_blacklist_status, info_completed_status, occupation_in_blacklist, first_review_admin_id, second_review_admin_id, final_review_admin_id, create_time, update_time, close_reason, reject_reason, analytic_result, profile, throttle_reason, test_flag, reject_code\n",
      "t_loan_app etldate, etlindex, id, customer_id, status, sub_status, full_name, credential_no, credential_type, loan_type, ifnull(amount,0) as amount, repayment_type, ifnull(service_fee,0) as service_fee, ifnull(pre_service_fee,0) as pre_service_fee, ifnull(interest_rate,0) as interest_rate, period, period_unit, effective_time, apply_for, apply_channel, apply_platform, comment, reviewer_id, create_time, update_time, paid_off_mode, parent_id, apply_purpose, imei, ip, ifnull(grace_period_rate,0) as grace_period_rate, ifnull(overdue_rate,0) as overdue_rate, ifnull(haircut,0) as haircut, haircut_issue_status, ifnull(haircut_rate,0) as haircut_rate, product_name, current_lpay_id, android_id, initial_loan_id, version_code, ifnull(default_fee_rate,0) as default_fee_rate, ifnull(default_factory,0) as default_factory, nper\n",
      "t_job_metric etldate, etlindex, id, job_name, uuid, duration, start_time, end_time, status, message, instance\n",
      "t_invitation etldate, etlindex, id, inviter_id, invitee_id, type, version, status, ifnull(reward,0) as reward, reward_type, disbursement_id, create_time, update_time, withdraw_history_id, risk_check, data_sources, data_level\n",
      "t_hit_blacklist_record etldate, etlindex, id, merchant_code, is_hit, status, hit_type, hit_content, fail_reason, id_address, param, create_time, update_time\n",
      "t_group etldate, etlindex, id, name, type, status, description, parent_id, create_time, update_time\n",
      "t_loan_issue etldate, etlindex, id, loan_app_id, customer_id, status, ifnull(issue_amount,0) as issue_amount, ifnull(reached_amount,0) as reached_amount, out_disbursement_no, disbursement_method, expire_time, reconcile_status, create_time, update_time, type, product_name\n",
      "t_loan_log etldate, etlindex, id, customer_id, loan_id, type, create_time\n",
      "t_mobile_tag_rel etldate, etlindex, id, mobile, tag_id, status, create_time, update_id, update_time, comment\n",
      "t_personal_info etldate, etlindex, id, customer_id, loan_app_id, full_name, gender, credential_no, credential_type, province, city, district, area, address, last_education, marital_status, children_number, residence_duration, family_name_in_law, facebook_id, car_number, house_number, ethnic, religion, nationality, ktp_gender, ktp_province, ktp_city, ktp_district, ktp_date_of_birth, ktp_analyze_status, status, create_time, update_time, email, backup_mobile\n",
      "t_message etldate, etlindex, id, customer_id, loan_app_id, trigger, status, sms_status, app_push_status, app_inbox_status, message_body, create_time, update_time, voice_status\n",
      "t_lpay_deposit etldate, etlindex, id, lpay_id, customer_id, status, ifnull(deposit_amount,0) as deposit_amount, ifnull(arrived_amount,0) as arrived_amount, ifnull(cleared_amount,0) as cleared_amount, deposit_channel, out_deposit_no, payment_code, deposit_method, reconcile_status, create_time, update_time, type, subtype, transaction_time\n",
      "t_lpay etldate, etlindex, id, loan_app_id, status, current_period, total_period, ifnull(principal_accr,0) as principal_accr, ifnull(principal_paid,0) as principal_paid, ifnull(interest_accr,0) as interest_accr, ifnull(interest_paid,0) as interest_paid, ifnull(default_accr,0) as default_accr, ifnull(default_paid,0) as default_paid, ifnull(service_fee_accr,0) as service_fee_accr, ifnull(service_fee_paid,0) as service_fee_paid, due_date, last_punishment_time, create_time, update_time, ifnull(rollover_fee_accr,0) as rollover_fee_accr, ifnull(rollover_fee_paid,0) as rollover_fee_paid, ifnull(erase_amount,0) as erase_amount, ifnull(default_fee_accr,0) as default_fee_accr, ifnull(default_fee_paid,0) as default_fee_paid, ifnull(rollover_principal_paid,0) as rollover_principal_paid, ifnull(rollover_principal_accr,0) as rollover_principal_accr, ifnull(coupon_amount,0) as coupon_amount, ifnull(rollover_principal_rate,0) as rollover_principal_rate\n",
      "t_login_log etldate, etlindex, id, customer_id, mobile, imei, ip, create_time, update_time, version_code, channel_key\n",
      "t_loan_tag_rel etldate, etlindex, id, loan_id, tag_id, status, create_time, update_id, update_time, comment\n",
      "t_record_contact etldate, etlindex, id, customer_id, name, mobile, relation, create_time, update_time, status, contact_priority\n",
      "t_record_bankcard etldate, etlindex, id, customer_id, card_no, bank_code, create_time, update_time\n",
      "t_send_coupon_rel etldate, etlindex, id, sub_type, tag_id, customer_id, coupon_type, structure, use_start_time, use_end_time, operator_id, create_time, result\n",
      "t_review_step_execution etldate, etlindex, id, loan_app_id, admin_id, step_id, status, trigger_status, run_mode, result, result_status, create_time, update_time\n",
      "t_review_blacklist etldate, etlindex, id, admin_id, status, type, value, reason, create_time, extension_value, source\n",
      "t_reduce etldate, etlindex, id, customer_id, loan_app_id, lpay_id, deposit_id, reduce_status, reduce_type, ifnull(reduce_amount,0) as reduce_amount, expired_time, create_time, update_time, body\n",
      "t_record_personal_info etldate, etlindex, id, customer_id, full_name, gender, credential_no, credential_type, province, city, district, area, address, family_name_in_law, facebook_id, last_education, marital_status, children_number, residence_duration, create_time, update_time, status, province_code, city_code, district_code, area_code, email, backup_mobile, apply_purpose, residence_status\n",
      "t_record_file etldate, etlindex, id, customer_id, file_type, file_kind, path, metadata, create_time, update_time, status\n",
      "t_record_employment etldate, etlindex, id, customer_id, company_name, company_province, company_city, company_district, company_area, company_address, company_phone, profession, salary, work_email, create_time, update_time, salary_day, t_employment, status, company_province_code, company_city_code, company_district_code, company_area_code\n",
      "t_sms etldate, etlindex, id, sender, send_trigger, sendto, code, content, status, response, create_time, update_time, send_id\n",
      "t_virtual_account etldate, etlindex, id, customer_id, channel, bank_code, type, account_number, unique_id, create_time, product_name\n",
      "t_thirdparty_data etldate, etlindex, id, customer_id, loan_id, data_type, channel, result, request_id, response, create_time, deleted\n",
      "t_tongdun_data etldate, etlindex, id, customer_id, status, channel, task_id, response, create_time, update_time\n",
      "t_test_customer etldate, etlindex, id, customer_id, status, create_time, update_time\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#notification导表到notification_etl_s3\n",
    "from concurrent import futures\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime,timedelta\n",
    "import pytz\n",
    "import json\n",
    "import pytz\n",
    "import hmac\n",
    "import pyspark.sql.functions as F\n",
    "from hashlib import sha256 \n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# print(datetime.now(pytz.timezone(\"Asia/Shanghai\")).strftime( '%Y-%m-%d'))\n",
    "today=(datetime.now()+ timedelta(-1)).strftime( '%Y-%m-%d')\n",
    "yesterday=(datetime.now(pytz.timezone(\"Asia/Shanghai\"))+ timedelta(-1)).strftime( '%Y-%m-%d')\n",
    "tablemap={\"banda_stream_etl\":\"banda\"} #,\n",
    "# ,\"banda_stream_etl\":\"1\"\n",
    "tablesql_1=\" FROM  (   SELECT    *  , row_number() OVER (PARTITION BY id  ORDER BY date_format(etldate,'yyyy-MM-dd HH:mm:ss.SSS') DESC  , if(etlindex is null ,0,etlindex)  desc)  row_num FROM  \"\n",
    "tablesql_2=\" ORDER BY id  ASC )  a  WHERE a.row_num = 1   AND a.kind <> 'delete' \"\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Python Demo\")\\\n",
    "    .config(\"hive.metastore.client.factory.class\", \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\") \\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n",
    "#     spark.conf.set(\"spark.scheduler.mode\",\"FAIR\")\n",
    "# 替换手机号\n",
    "def get_secret_obj():\n",
    "    df=spark.read.text(\"s3://rupiahplus-configs/etl/data_secrt/col.json\").collect()\n",
    "    keymap=''\n",
    "    for  row in df:\n",
    "        keymap=keymap+row['value']\n",
    "    json_content=json.loads(keymap)\n",
    "    return json_content\n",
    "colmap= get_secret_obj()\n",
    "mobileType=colmap[\"mobileType\"]\n",
    "def getRelmobile(colNm,str):\n",
    "    if colNm in mobileType:\n",
    "        relmobile = str.strip().replace(\"+\", \"\").replace(\"-\", \"\").replace(\" \", \"\").replace('\"', '')\n",
    "        if (relmobile.startswith(\"62\")):\n",
    "            relmobile = relmobile.replace(\"62\", \"0\",1)\n",
    "        if relmobile.startswith(\"0\") == False:\n",
    "            relmobile = \"0\" + relmobile;\n",
    "        return relmobile\n",
    "    return str\n",
    "# hmac_256加密\n",
    "def hmac_sha256(key,colNm,value):\n",
    "    if value!=None:\n",
    "#         处理手机号\n",
    "        rtn=getRelmobile(colNm,value)\n",
    "        h = hmac.new(key.encode('utf-8'),digestmod=sha256)\n",
    "        h.update(rtn.encode('utf-8'))\n",
    "        h_str = h.hexdigest()\n",
    "        return h_str\n",
    "    return \"\"\n",
    "spark.udf.register(\"hmac_sha256\",hmac_sha256,T.StringType())\n",
    "def getTableColum(b):\n",
    "    colum=\"\"\n",
    "    for index in range(len(b)):\n",
    "        if(index>0 and index<len(b)-8):   \n",
    "            colum=colum+setDef(b[index][\"data_type\"],b[index][\"col_name\"])+\", \"\n",
    "    return colum[0:len(colum)-2]\n",
    "def setDef(type,table_col):\n",
    "    if(type[:7] == 'decimal'):\n",
    "        return \"ifnull(\"+table_col+\",0) as \"+table_col\n",
    "    else:\n",
    "        return table_col\n",
    "def add_secret_col(dbType,tableNm,col):\n",
    "    secret_Col=[]\n",
    "    if colmap.get(dbType)!=None and colmap[dbType]!=None and colmap[dbType].get(tableNm)!=None:\n",
    "        secret_Col=colmap[tablemap[databaseName]][tableNm]\n",
    "    sh256Col =col\n",
    "    hmac_key=colmap[\"hmac_key\"]\n",
    "#     sql=\"select hmac_sha256('{hmac_key}','123456789') as sh2\".format(hmac_key=hmac_key)\n",
    "    for i in secret_Col:\n",
    "        sh256Col=sh256Col+ \", hmac_sha256('{hmac_key}','\"+i+\"', \"+i+\") \"+ i+\"_x\"\n",
    "    return sh256Col.format(hmac_key=hmac_key)\n",
    "def make_col_temptable(databaseName,row):\n",
    "    tableName=row[\"tableName\"]\n",
    "    tablecolum=\"desc \" +databaseName+\".\"+tableName;\n",
    "    tableSchema= spark.sql(tablecolum).collect()\n",
    "    colNm=getTableColum(tableSchema)\n",
    "    print(tableName,colNm)\n",
    "print(__name__)\n",
    "if __name__ == \"builtins\":\n",
    "#     注册udf\n",
    "    spark.udf.register(\"hmac_sha256\",hmac_sha256,T.StringType())\n",
    "    spark.conf.set(\"spark.sql.shuffle.partitions\",20)\n",
    "    for databaseName in tablemap:\n",
    "        print(databaseName)\n",
    "        databasesql=\"show tables in \"+\"banda_stream_etl\"\n",
    "        tables=spark.sql(databasesql)\n",
    "        tablelist=tables.collect();\n",
    "        executor=None\n",
    "        with futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            futures_result=futures.wait([executor.submit(make_col_temptable,databaseName, tableNm) for tableNm in tablelist])\n",
    "            for  future in futures_result[0]:\n",
    "                print(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99a19e23b1a4684ba802304593518ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-24\n",
      "2020-02-25\n",
      "2021-03-01 07:37:33.574391"
     ]
    }
   ],
   "source": [
    "from datetime import datetime,timedelta\n",
    "nowdate=(datetime(2020,2,24,23,4,12)).strftime('%Y-%m-%d')\n",
    "yesterday=(datetime(2020,2,25,3,5,12)).strftime('%Y-%m-%d')\n",
    "print(nowdate)\n",
    "print(yesterday)\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6e3f02c8fc47a1994f23fd26020dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "\n",
    "# t_whitelist_old_customerf2!Id\n",
    "#############################################################################################################################\n",
    "# builtins\n",
    "# __main__\n",
    "tableList={\"banda\":[\"*\"]}\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Python Demo\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "    tableConf={\n",
    "         \"banda\":{\n",
    "              \"url\" : \"jdbc:postgresql://pgm-d9jkp19xeyji7eat.pgsql.ap-southeast-5.rds.aliyuncs.com:3433/banda\",\n",
    "              \"user\":\"postgres\",\n",
    "              \"password\":\"vHeqPwro2HriV7CrM8Wh\",\n",
    "              \"type\": \"banda\",\n",
    "              \"ls\":[\n",
    "                    {\"tablenm\":\"t_admin_audit\", \"lowerbound\":100000, \"upperbound\":44811409, \"index\":1}, \n",
    "                \n",
    "              ]\n",
    "        }\n",
    "    }\n",
    "    for dbtype in tableList.keys():\n",
    "        print(dbtype ,tableList[dbtype])\n",
    "        if tableConf.get(dbtype):\n",
    "            ls=[]\n",
    "            for table in tableList[dbtype]:\n",
    "                url = tableConf[dbtype][\"url\"]\n",
    "                user = tableConf[dbtype][\"user\"]\n",
    "                password = tableConf[dbtype][\"password\"]\n",
    "                tbtype = tableConf[dbtype][\"type\"]\n",
    "                if table=='*':\n",
    "                    ls = tableConf[dbtype][\"ls\"]\n",
    "                else:\n",
    "                    ls=ls+[tb for tb in tableConf[dbtype][\"ls\"] if tb[\"tablenm\"]==table]\n",
    "            for row in ls:\n",
    "                tableNm=row[\"tablenm\"]\n",
    "                lowerBound=row[\"lowerbound\"]\n",
    "                upperBound=row[\"upperbound\"]\n",
    "#                 df = spark.read.format(\"jdbc\").option(\"url\", url).option(\"user\", user).option(\"password\", password).option(\"query\", \"select max(id) max, min(id) min from t_admin_audit \").load()\n",
    "                df = spark.read.format(\"jdbc\").option(\"url\", url).option(\"user\", user).option(\"password\", password).option(\"query\", \"select max(id) max, min(id) from t_admin_audit as tmp\").load()\n",
    "                df.createOrReplaceTempView(\"t\")\n",
    "                bound = spark.sql(\"select * from t\")\n",
    "                bound.show()\n",
    "                print(1)\n",
    "#                 max = bound.collect()[0].max\n",
    "#                 min = bound.collect()[0].min\n",
    "#                 if type(max)==int and type(min)==int and max>min:\n",
    "#                     df_table = spark.read.format(\"jdbc\").option(\"url\", url).option(\"dbtable\",  tableNm).option(\"user\", user).option(\"password\", password).option(\"partitionColumn\", \"id\").option(\"lowerBound\", min).option(\"upperBound\", max).option(\"numPartitions\", 1000).load()\n",
    "#                     path=\"s3://rupiahplus-data-warehouse/aliyun/\"+tbtype+\"_emr/\"+tableNm\n",
    "#                     df_table.write.mode(\"overwrite\").orc(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0a9bdbfaa042908d3829d61f41ded6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6</td><td>application_1623740876860_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-3-0-40.ap-southeast-1.compute.internal:20888/proxy/application_1623740876860_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-3-0-67.ap-southeast-1.compute.internal:8042/node/containerlogs/container_1623740876860_0007_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+------------------+--------------------+---+\n",
      "|     id|             task_id|                name|               value|inner_reference_id|         create_time| rk|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+--------------------+---+\n",
      "|  12337|6ade76ab-3cb6-44e...|              dc3610|\"company_answer_p...|             10039|2020-07-09 03:56:...|  1|\n",
      "|   8580|6ade76ab-3cb6-44e...|       rejected_time|                   3|             10042|2020-07-08 11:24:...|  1|\n",
      "|1698737|23799d78-a246-5bc...|              dc3602|            \"reject\"|             10107|2020-07-30 02:47:...|  1|\n",
      "|1705140|9bf7f6a1-b2da-507...|              dc3605|            \"reject\"|             10111|2020-07-30 06:57:...|  1|\n",
      "| 270899|79994416-5c3a-5db...|same_device_proce...|                   0|             10119|2020-07-25 02:46:...|  1|\n",
      "|1928162|37d6d2c5-9711-517...|cash_loan_history...|                   0|             10140|2020-08-11 10:58:...|  1|\n",
      "|1706604|e391eb28-73bd-5ea...|same_device_proce...|                   0|             10153|2020-08-01 08:49:...|  1|\n",
      "| 764171|4f719163-671c-585...|same_ktp_processi...|                   0|             10169|2020-07-29 09:29:...|  1|\n",
      "|1966750|c8860141-f9e8-5d6...|same_wifi_apply_i...|                   0|             10175|2020-08-14 08:02:...|  1|\n",
      "|1965785|f83e080a-1330-5f7...|               dc311|            \"reject\"|             10176|2020-08-14 07:53:...|  1|\n",
      "| 765070|51d6c2be-c1cf-563...|            order_id|               10197|             10197|2020-07-29 09:29:...|  1|\n",
      "|1703145|2ea1b3c7-e95f-5fa...|crawl_identity_check|       \"EXACT_MATCH\"|             10220|2020-07-30 03:49:...|  1|\n",
      "|1708922|1b034093-2839-5df...|                 age|                  32|             10257|2020-08-02 06:15:...|  1|\n",
      "| 278769|b1cda4b7-b4ef-5ac...|        company_name|\"WARUNG BAKSO BER...|             10286|2020-07-25 14:53:...|  1|\n",
      "| 279629|4d437bfe-c844-5bb...|   bio_compare_score|                   0|             10303|2020-07-25 17:34:...|  1|\n",
      "| 335288|2aa8bbaa-f5ca-584...|same_mobile_proce...|                   0|             10331|2020-07-27 10:29:...|  1|\n",
      "| 334434|7b09590c-4fdd-592...|                 age|                  35|             10335|2020-07-27 09:09:...|  1|\n",
      "|1883344|a4e3a393-0bb6-5f9...|       customer_type|            \"normal\"|             10337|2020-08-11 10:37:...|  1|\n",
      "| 357621|99191438-e6f0-550...|            order_id|               10356|             10356|2020-07-29 02:45:...|  1|\n",
      "| 281720|225cf755-a5e5-5d5...|same_ktp_processi...|                   0|             10387|2020-07-27 03:25:...|  1|\n",
      "+-------+--------------------+--------------------+--------------------+------------------+--------------------+---+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from (select\n",
    "\t\t\tid, -- 变量顺序id\n",
    "\t\t\ttask_id, -- 任务id\n",
    "\t\t\tname, -- 变量名\n",
    "\t\t\tvalue, -- 变量值\n",
    "\t\t\tinner_reference_id, -- 订单id\n",
    "\t\t\tcreate_time, -- 创建时间\n",
    "\t\t\trow_number() over(partition by inner_reference_id,name order by id desc) as rk -- 最新标识\n",
    "\t\tfrom credinex_guest.t_risk_param\n",
    ") rtn\n",
    "where  rtn.rk=1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc5c4a9c42b440295762bf47691f9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1627368337512_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-3-0-98.ap-southeast-1.compute.internal:20888/proxy/application_1627368337512_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-3-0-25.ap-southeast-1.compute.internal:8042/node/containerlogs/container_1627368337512_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|           datetime|\n",
      "+---+-------------------+\n",
      "| id|               date|\n",
      "|  1|2021-07-01 12:12:12|\n",
      "|  1|2021-07-02 12:12:12|\n",
      "|  1|2021-07-03 12:12:12|\n",
      "|  1|2021-07-04 12:12:12|\n",
      "|  1|2021-07-05 12:12:12|\n",
      "|  1|2021-07-06 12:12:12|\n",
      "|  1|2021-07-07 12:12:12|\n",
      "|  1|2021-07-08 12:12:12|\n",
      "|  1|2021-07-09 12:12:12|\n",
      "|  1|2021-07-10 12:12:12|\n",
      "|  1|2021-07-02 12:12:12|\n",
      "|  1|2021-07-02 12:12:12|\n",
      "|  2|2021-07-01 12:12:12|\n",
      "|  2|2021-07-02 12:12:12|\n",
      "|  2|2021-07-02 12:12:12|\n",
      "|  2|2021-07-03 12:12:12|\n",
      "|  2|2021-07-04 12:12:12|\n",
      "|  3|2021-07-01 12:12:12|\n",
      "|  3|2021-07-02 12:12:12|\n",
      "+---+-------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from han_test.user_login \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0769e65ac6d7484ab19d53bd1a5a0649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----------+\n",
      "|id |rtn|diff      |\n",
      "+---+---+----------+\n",
      "|1  |10 |2021-06-30|\n",
      "+---+---+----------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select id,count(diff) as rtn ,diff  from(\n",
    "    select  id,datetime,rnk,date(datetime)-rnk as diff  from (\n",
    "     select  * ,row_number() over(partition by id order by datetime) as rnk\n",
    "            from (\n",
    "                select distinct id,substr(datetime,1,10) as datetime from han_test.user_login \n",
    "            ) t\n",
    "            where  id <> 'id') t1  \n",
    ")t2\n",
    "group by id,diff\n",
    "having rtn>7\n",
    "\"\"\").show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9727c53eddfc4b34be21863c38b93b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "| id|count(diff)|\n",
      "+---+-----------+\n",
      "|  7|          2|\n",
      "|  3|          2|\n",
      "|  3|          4|\n",
      "|  6|          1|\n",
      "|  1|         10|\n",
      "|  8|          1|\n",
      "|  5|          1|\n",
      "|  4|          2|\n",
      "|  2|          4|\n",
      "+---+-----------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "       select id,count(diff)  from (select id, date(datetime)- rnk as diff from (\n",
    "           select  * ,row_number() over(partition by id order by datetime) as rnk\n",
    "            from \n",
    "                select distinct id,substr(datetime,1,10) as datetime from han_test.user_login \n",
    "            ) t\n",
    "            where  id <> 'id') t1  ) t2\n",
    "        group by t2.id,t2.diff\n",
    "    \n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aadf7f4561d4b29bac65f5c0e7c7ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|rtn|\n",
      "+---+---+\n",
      "|  1| 10|\n",
      "+---+---+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select id,count(diff) as  rtn from (\n",
    " select t1.*,date(datetime)- rnk as diff from(\n",
    "     select *,row_number() over(partition by id order by datetime) as rnk from (\n",
    "       select  distinct id,substr(datetime,1,10) as datetime  from han_test.user_login\n",
    "     )t\n",
    " )t1\n",
    ")t2\n",
    "group by id,diff\n",
    "having rtn>9\n",
    " \n",
    " \n",
    " \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1effa4ff07045d18c088d26830aa203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "|id |datetime           |\n",
      "+---+-------------------+\n",
      "|7  |2021-07-04 12:12:12|\n",
      "|7  |2021-07-05 12:12:12|\n",
      "|3  |2021-07-06 12:12:12|\n",
      "|3  |2021-07-05 12:12:12|\n",
      "|3  |2021-07-02 12:12:12|\n",
      "|3  |2021-07-01 12:12:12|\n",
      "|3  |2021-07-04 12:12:12|\n",
      "|3  |2021-07-07 12:12:12|\n",
      "|6  |2021-07-01 12:12:12|\n",
      "|1  |2021-07-02 12:12:12|\n",
      "|1  |2021-07-09 12:12:12|\n",
      "|1  |2021-07-08 12:12:12|\n",
      "|1  |2021-07-07 12:12:12|\n",
      "|1  |2021-07-10 12:12:12|\n",
      "|1  |2021-07-05 12:12:12|\n",
      "|1  |2021-07-06 12:12:12|\n",
      "|1  |2021-07-01 12:12:12|\n",
      "|1  |2021-07-04 12:12:12|\n",
      "|1  |2021-07-03 12:12:12|\n",
      "|1  |2021-07-02 12:12:12|\n",
      "|1  |2021-07-02 12:12:12|\n",
      "|8  |2021-07-01 12:12:12|\n",
      "|5  |2021-07-02 12:12:12|\n",
      "|4  |2021-07-02 12:12:12|\n",
      "|4  |2021-07-01 12:12:12|\n",
      "|2  |2021-07-03 12:12:12|\n",
      "|2  |2021-07-04 12:12:12|\n",
      "|2  |2021-07-01 12:12:12|\n",
      "|2  |2021-07-02 12:12:12|\n",
      "|2  |2021-07-02 12:12:12|\n",
      "+---+-------------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  select  * from  han_test.user_login a\n",
    "   left semi join  han_test.user_login b \n",
    "    on a.id=b.id\n",
    "where a.id <> 'id'\n",
    "\"\"\").show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91579e2062a34561b65d972f072130e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    " SELECT * FROM `id_adapundi_data_input`.`adapundi_daily_interest_cost_of_fund` where date <> to_date('2020-10-08')\n",
    "\"\"\").write.mode(\"append\").orc(\"s3://rupiahplus-data-warehouse/aliyun/adapundi_data_input/adapundi_daily_interest_cost_of_fund/year=2021/month=02/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce91e340bb64d799a6548d76d9e185a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+\n",
      "| id|      min(datetime)|      max(datetime)|\n",
      "+---+-------------------+-------------------+\n",
      "|  7|2021-07-04 12:12:12|2021-07-05 12:12:12|\n",
      "|  3|2021-07-01 12:12:12|2021-07-07 12:12:12|\n",
      "|  6|2021-07-01 12:12:12|2021-07-01 12:12:12|\n",
      "|  1|2021-07-01 12:12:12|2021-07-10 12:12:12|\n",
      "|  8|2021-07-01 12:12:12|2021-07-01 12:12:12|\n",
      "|  5|2021-07-02 12:12:12|2021-07-02 12:12:12|\n",
      "|  4|2021-07-01 12:12:12|2021-07-02 12:12:12|\n",
      "|  2|2021-07-01 12:12:12|2021-07-04 12:12:12|\n",
      "+---+-------------------+-------------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select id, min(datetime) ,max(datetime) from han_test.user_login\n",
    "where id <> 'id'\n",
    "group by id \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73db0c80543463f97dc6c0d8087f014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+----+--------+\n",
      "| id|           datetime|  id|datetime|\n",
      "+---+-------------------+----+--------+\n",
      "|  7|2021-07-05 12:12:12|null|    null|\n",
      "|  3|2021-07-07 12:12:12|null|    null|\n",
      "|  6|2021-07-01 12:12:12|null|    null|\n",
      "|  1|2021-07-10 12:12:12|null|    null|\n",
      "| id|               date|null|    null|\n",
      "|  8|2021-07-01 12:12:12|null|    null|\n",
      "|  5|2021-07-02 12:12:12|null|    null|\n",
      "|  4|2021-07-02 12:12:12|null|    null|\n",
      "|  2|2021-07-04 12:12:12|null|    null|\n",
      "+---+-------------------+----+--------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select  * from han_test.user_login t1\n",
    "left join han_test.user_login t2\n",
    "on t1.id=t2.id\n",
    "and t1.datetime<t2.datetime\n",
    "where t2.datetime is null\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38024569c0f4de28a36e64b48882e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|  datetime|cnt|\n",
      "+----------+---+\n",
      "|2021-07-09|  1|\n",
      "|2021-07-08|  1|\n",
      "|2021-07-03|  2|\n",
      "|2021-07-05|  3|\n",
      "|2021-07-07|  2|\n",
      "|2021-07-10|  1|\n",
      "|2021-07-04|  4|\n",
      "|2021-07-06|  2|\n",
      "|2021-07-02|  8|\n",
      "|2021-07-01|  6|\n",
      "+----------+---+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "  select distinct date(datetime) as datetime ,count(id) over(partition by date (datetime) ) as cnt from han_test.user_login \n",
    "  where id <> 'id'\n",
    "\n",
    "\"\"\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
