{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e273d0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241ef4626c6b40dd969bfeb9f9f1992a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tSession 6 unexpectedly reached final status 'dead'. See logs:\n",
      "stdout: \n",
      "#\n",
      "# There is insufficient memory for the Java Runtime Environment to continue.\n",
      "# Native memory allocation (mmap) failed to map 69599232 bytes for committing reserved memory.\n",
      "# An error report file with more information is saved as:\n",
      "# /tmp/hs_err_pid18135.log\n",
      "\n",
      "stderr: \n",
      "21/08/25 10:10:20 INFO RSCDriver: Connecting to: ip-10-3-0-76.ap-southeast-1.compute.internal:10000\n",
      "21/08/25 10:10:20 INFO RSCDriver: Starting RPC server...\n",
      "21/08/25 10:10:20 INFO RpcServer: Connected to the port 10002\n",
      "21/08/25 10:10:20 WARN RSCConf: Your hostname, ip-10-3-0-76.ap-southeast-1.compute.internal, resolves to a loopback address, but we couldn't find any external IP address!\n",
      "21/08/25 10:10:20 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.\n",
      "21/08/25 10:10:21 INFO RSCDriver: Received job request 23f0b95a-bfd9-4c98-8202-bf958a21d40d\n",
      "21/08/25 10:10:21 INFO RSCDriver: SparkContext not yet up, queueing job request.\n",
      "OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x000000055b514000, 69599232, 0) failed; error='Cannot allocate memory' (errno=12)\n",
      "\n",
      "YARN Diagnostics: \n",
      "spark-submit start failed.\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timedelta\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pytz\n",
    "# print(__name__)builtins\n",
    "if __name__ == \"builtins\":\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Demo\") \\\n",
    "        .config(\"hive.metastore.client.factory.class\",\n",
    "                \"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory\") \\\n",
    "        .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "    spark.conf.set(\"hive.exec.dynamic.partition.mode\", \"nonstrict\");\n",
    "    spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "    spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"20000000\")\n",
    "    databases = spark.sql(\"show databases\")\n",
    "    databases = databases.collect()\n",
    "    tablelist=[\"`banda-etl-s3`.`t_channel_details`\",\"`banda-etl-s3`.`t_customer_install_info`\",\"`banda-etl-s3`.`t_customer`\"];\n",
    "    df1=spark.sql(\"\"\"\n",
    "                     with assign_detail as \n",
    "            (\n",
    "            SELECT  audit.admin_id\n",
    "                   ,audit.collector_id\n",
    "                   ,audit.trigger\n",
    "                   ,lpay.id\n",
    "                   ,lpay.erase_amount\n",
    "                   ,audit.full_name_x\n",
    "                   ,audit.loan_app_id\n",
    "                   ,audit.create_time\n",
    "                   ,audit.assign_stage\n",
    "                   ,app.amount\n",
    "                   ,lpay.due_date\n",
    "                   ,datediff(DATE(audit.create_time+interval'7'hour),DATE(lpay.due_date+interval'7'hour)) AS overduedays_assign --分案时逾期天数\n",
    "            FROM \n",
    "            (\n",
    "                SELECT  *\n",
    "                FROM banda_rpt_mid.t_assign_detail_stage_daily \n",
    "                WHERE rn_total_desc=1 --一个案件多次分案，仅计算最后一次分案记录作为在库案件记录 audit\n",
    "                AND datediff(DATE(now()+interval'7'hour),DATE(create_time+interval'7'hour))>=0 \n",
    "                AND datediff(DATE(now()+interval'7'hour), DATE(create_time + interval'2'hour+interval'7'hour))<DAY(now()+interval'7'hour) \n",
    "            ) audit\n",
    "            LEFT JOIN `banda-etl-s3`.t_loan_app app\n",
    "            ON app.id=audit.loan_app_id\n",
    "            LEFT JOIN `banda-etl-s3`.t_lpay lpay\n",
    "            ON lpay.loan_app_id=audit.loan_app_id\n",
    "            where datediff( DATE(audit.create_time+interval'7' hour), DATE(lpay.due_date+interval'7' hour))>-4 -- 分案日>到期日-4天\n",
    "            ),\n",
    "            paid_off_id as \n",
    "            (\n",
    "            SELECT  app2.id\n",
    "            FROM `banda-etl-s3`.t_loan_app app2\n",
    "            LEFT JOIN `banda-etl-s3`.t_loan_app_status_log lg\n",
    "            ON lg.loan_app_id=app2.id\n",
    "            WHERE app2.product_name='RUPIAHONE' \n",
    "            AND lg.create_time+interval'7'hour >now()+INTERVAL '-24' hour +INTERVAL'-2' month +interval'7'hour\n",
    "            AND lg.new_status='PAID_OFF' \n",
    "            AND app2.status IN ('CURRENT', 'GRACE_PERIOD', 'OVERDUE', 'PAID_OFF') \n",
    "            AND datediff( DATE(now()+interval'7'hour ), DATE(lg.create_time+interval'7'hour ))>0  \n",
    "            )\n",
    "\n",
    "\n",
    "            -- 创建当下在库案件量增量表，每日插入当日数据，保留之前数据\n",
    "            -- banda_rpt_mid.t_case_in_collection_increment \n",
    "            SELECT  date_format(now()+INTERVAL'7' hour,'yyyy-MM-dd') AS DATE \n",
    "                   ,t3.collector_id \n",
    "                   ,t3.full_name_x \n",
    "                   ,assign_stage\n",
    "                   ,COUNT(DISTINCT t3.loan_app_id)                                                                                                         AS count \n",
    "                   ,SUM(CASE WHEN t3.principal_paid IS NULL THEN t3.amount ELSE t3.amount-t3.principal_paid END )                                          AS unpaid_amoun\n",
    "                   ,now() as insert_time\n",
    "            FROM \n",
    "            (\n",
    "                SELECT  t1.loan_app_id \n",
    "                       ,t1.collector_id \n",
    "                       ,t1.full_name_x \n",
    "                       ,t1.due_date \n",
    "                       ,t1.amount \n",
    "                       ,t1.assign_stage\n",
    "                       ,SUM(clear.principal) AS principal_paid\n",
    "                FROM assign_detail t1\n",
    "                LEFT JOIN paid_off_id t2\n",
    "                ON t2.id=t1.loan_app_id\n",
    "                LEFT JOIN `banda-etl-s3`.t_lpay_deposit deposit\n",
    "                ON deposit.lpay_id=t1.id AND deposit.status='CLEARED' AND deposit.create_time<t1.create_time AND \n",
    "                ( deposit.deposit_method !='DIRECT_TRANSFER' OR (deposit.deposit_method ='DIRECT_TRANSFER' AND deposit.cleared_amount !=ceil(t1.erase_amount)))\n",
    "                LEFT JOIN `banda-etl-s3`.t_reduce reduce\n",
    "                ON reduce.deposit_id =deposit.id AND reduce.reduce_status='SUCCEED'\n",
    "                LEFT JOIN `banda-etl-s3`.t_clear_detail_log clear\n",
    "                ON clear.deposit_id=deposit.id\n",
    "                WHERE  t2.id IS NULL \n",
    "                AND (reduce.reduce_type IS NULL OR reduce.reduce_type NOT IN ('DELAY_CALLBACK', 'NONE_CALLBACK_REDUCE', 'COLLECTION_REDUCE')) \n",
    "                GROUP BY  t1.loan_app_id \n",
    "                         ,t1.collector_id \n",
    "                         ,t1.full_name_x \n",
    "                         ,t1.due_date \n",
    "                         ,t1.amount \n",
    "                         ,t1.assign_stage\n",
    "            )t3\n",
    "            GROUP BY  date_format(now()+INTERVAL'7' hour,'yyyy-MM-dd') \n",
    "                     ,t3.collector_id \n",
    "                     ,t3.full_name_x \n",
    "                     ,assign_stage\"\"\")\n",
    "                  \n",
    "    df1.repartition(1).write.mode(\"append\").orc(\"s3://rupiahplus-data-warehouse/etl/banda/report_temp_table/t_case_in_collection_increment/\") \n",
    "    df2=spark.sql(\"\"\"-- 新建表：banda_rpt_mid.coll_outsouring_detail_daily\n",
    "                    -- 增量更新，每日新增数据进去，之前数据保留\n",
    "                    SELECT  date(now()+interval '-1'day+ INTERVAL '7' hour) AS DATE\n",
    "                           ,t4.collector_id\n",
    "                           ,t4.full_name\n",
    "                           ,t4.overdue\n",
    "                           ,t4.gp_name\n",
    "                           ,COUNT(DISTINCT t4.loan_app_id) AS count\n",
    "                           ,SUM(t4.unpaid_amount)          AS unpaid_amount\n",
    "                           ,SUM(t4.unpaid_total)           AS unpaid_total\n",
    "                           ,now() as insert_time\n",
    "                    FROM\n",
    "                    (\n",
    "                        SELECT  t3.collector_id\n",
    "                               ,t3.full_name\n",
    "                               ,t3.overdue\n",
    "                               ,t3.gp_name\n",
    "                               ,t3.loan_app_id\n",
    "                               ,t3.create_time\n",
    "                               ,t3.amount\n",
    "                               ,t3.clear_amount\n",
    "                               ,t3.clear_principal\n",
    "                               ,CASE WHEN t3.clear_principal IS NULL THEN t3.amount  ELSE t3.amount-t3.clear_principal END AS unpaid_amount\n",
    "                               ,CASE WHEN t3.clear_total IS NULL THEN t3.total_accr  ELSE t3.total_accr-t3.clear_total END AS unpaid_total\n",
    "                               ,row_number()OVER (PARTITION BY t3.loan_app_id,t3.gp_name ORDER BY t3.create_time ASC )as num2--一个组第一次分案记录\n",
    "                        FROM\n",
    "                        (\n",
    "                            SELECT  t2.collector_id\n",
    "                                   ,t2.full_name\n",
    "                                   ,t2.overdue\n",
    "                                   ,t2.gp_name\n",
    "                                   ,t2.loan_app_id\n",
    "                                   ,t2.amount\n",
    "                                   ,t2.total_accr\n",
    "                                   ,t2.create_time\n",
    "                                   ,SUM(deposit.cleared_amount)                                         AS clear_amount\n",
    "                                   ,SUM(clear.principal)                                                AS clear_principal\n",
    "                                   ,SUM(clear.principal+clear.interest+clear.penalty+clear.default_fee) AS clear_total\n",
    "                            FROM\n",
    "                            (\n",
    "                                SELECT  t1.loan_app_id\n",
    "                                       ,t1.collector_id\n",
    "                                       ,t1.full_name\n",
    "                                       ,t1.gp_name\n",
    "                                       ,t1.overdue\n",
    "                                       ,t1.amount\n",
    "                                       ,t1.total_accr\n",
    "                                       ,t1.create_time\n",
    "                                       ,t1.id\n",
    "                                       ,t1.erase_amount\n",
    "                                       ,row_number()OVER (PARTITION BY t1.loan_app_id,t1.overdue ORDER BY t1.create_time DESC )AS num--一个逾期阶段最后一次分案记录\n",
    "                                FROM\n",
    "                                (\n",
    "                                    SELECT  audit.admin_id\n",
    "                                           ,audit.collector_id\n",
    "                                           ,ad.full_name_x                                                                                                                 AS full_name\n",
    "                                           ,audit.loan_app_id\n",
    "                                           ,audit.create_time\n",
    "                                           ,app.amount\n",
    "                                           ,lpay.principal_accr+lpay.interest_accr+lpay.default_accr+lpay.default_fee_accr                                                 AS total_accr\n",
    "                                           ,lpay.due_date\n",
    "                                           ,lpay.id\n",
    "                                           ,lpay.erase_amount\n",
    "                                           ,substr(depart.name,-2)                                                                                                         AS gp_name\n",
    "                                           ,CASE WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>179 THEN 180\n",
    "                                                 WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>89 THEN 90\n",
    "                                                 WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>60 THEN 61\n",
    "                                                 WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>31 THEN 32  ELSE 31 END AS overdue\n",
    "                                    FROM banda_rpt_mid.t_assign_detail_stage_daily audit\n",
    "                                    LEFT JOIN `banda-etl-s3`.t_admin ad\n",
    "                                    ON ad.id=audit.collector_id\n",
    "                                    LEFT JOIN `banda-etl-s3`.t_admin_group ad_group\n",
    "                                    ON ad_group.admin_id=audit.collector_id AND ad_group.status='ACTIVE'\n",
    "                                    LEFT JOIN `banda-etl-s3`.t_department_group depart\n",
    "                                    ON depart.id=ad_group.group_id AND depart.status='ACTIVE'\n",
    "                                    LEFT JOIN `banda-etl-s3`.t_loan_app app\n",
    "                                    ON app.id=audit.loan_app_id\n",
    "                                    LEFT JOIN `banda-etl-s3`.t_lpay lpay\n",
    "                                    ON lpay.loan_app_id=audit.loan_app_id\n",
    "                                    WHERE datediff(date(now()+ INTERVAL '7' hour), date(audit.create_time+ INTERVAL '7' hour) )>0\n",
    "                                    AND datediff(date(now()+INTERVAL'-24' hour+ INTERVAL '7' hour), date(audit.create_time + INTERVAL '2' hour+ INTERVAL '7' hour))<day(now()+INTERVAL'-24'hour+ INTERVAL '7' hour)\n",
    "                                    AND datediff( date(audit.create_time + INTERVAL '2' hour+ INTERVAL '7' hour), date(lpay.due_date+ INTERVAL '7' hour))>30\n",
    "                                    AND depart.name is NOT NULL\n",
    "                                )t1\n",
    "                            )t2\n",
    "                            LEFT JOIN `banda-etl-s3`.t_lpay_deposit deposit\n",
    "                            ON deposit.lpay_id=t2.id AND deposit.status='CLEARED' AND deposit.create_time<t2.create_time \n",
    "                            AND ( deposit.deposit_method !='DIRECT_TRANSFER' OR (deposit.deposit_method ='DIRECT_TRANSFER' AND deposit.cleared_amount !=ceil(t2.erase_amount)))\n",
    "                            LEFT JOIN `banda-etl-s3`.t_reduce reduce\n",
    "                            ON reduce.deposit_id =deposit.id AND reduce.reduce_status='SUCCEED'\n",
    "                            LEFT JOIN `banda-etl-s3`.t_clear_detail_log clear\n",
    "                            ON clear.deposit_id=deposit.id\n",
    "                            WHERE t2.num=1\n",
    "                            AND (reduce.reduce_type IS NULL OR reduce.reduce_type NOT IN ('DELAY_CALLBACK', 'NONE_CALLBACK_REDUCE', 'COLLECTION_REDUCE'))\n",
    "                            GROUP BY  t2.collector_id\n",
    "                                     ,t2.full_name\n",
    "                                     ,t2.overdue\n",
    "                                     ,t2.gp_name\n",
    "                                     ,t2.loan_app_id\n",
    "                                     ,t2.amount\n",
    "                                     ,t2.total_accr\n",
    "                                     ,t2.create_time\n",
    "                        )t3\n",
    "                    )t4\n",
    "                    WHERE t4.num2=1\n",
    "                    GROUP BY  date(now()+interval '-1'day+ INTERVAL '7' hour)\n",
    "                             ,t4.collector_id\n",
    "                             ,t4.full_name\n",
    "                             ,t4.overdue\n",
    "                             ,t4.gp_name \"\"\")\n",
    "    df2.repartition(1).write.mode(\"append\").orc(\"s3://rupiahplus-data-warehouse/etl/banda/report_temp_table/coll_outsouring_detail_daily/\")\n",
    "    df3=spark.sql(\"\"\"\n",
    "            -- 创建日分区表 banda_rpt_mid.coll_collector_info_detail_dt\n",
    "            -- 每日数据存为一个分区保留记录\n",
    "            -- partition by dt\n",
    "\n",
    "            SELECT  t2.collector_id\n",
    "                   ,t2.full_name_x\n",
    "                   ,substring_index(full_name_x,\"-\",1) AS collector_name\n",
    "                   ,assign_stage\n",
    "                   ,t2.team_leader_name\n",
    "                   ,group_name\n",
    "                   ,t2.team_name\n",
    "                   ,NOW() as insert_time,\n",
    "                   date(now()) as date_time\n",
    "            FROM\n",
    "            (\n",
    "                SELECT  audit.*\n",
    "                       ,ad.team_leader_id\n",
    "                       ,depart.description AS team_name\n",
    "                       ,depart.name        AS group_name\n",
    "                       ,depart2.description\n",
    "                       ,ad2.full_name_x    AS team_leader_name\n",
    "                FROM\n",
    "                ( select*from banda_rpt_mid.t_assign_detail_stage_daily\n",
    "                    WHERE rn_ingroup_desc=1 \n",
    "                ) audit\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin ad\n",
    "                ON ad.id=audit.collector_id\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin_group ad_group\n",
    "                ON ad_group.admin_id=audit.collector_id AND ad_group.status= 'ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_department_group depart\n",
    "                ON depart.id=ad_group.group_id AND depart.status='ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_department_group depart2\n",
    "                ON depart2.id=depart.parent_id AND depart2.status='ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin_group ad_group2\n",
    "                ON ad_group2.group_id=depart2.id AND ad_group2.status='ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin ad2\n",
    "                ON ad2.id=ad_group2.admin_id\n",
    "                WHERE depart.name IS NOT NULL\n",
    "                AND DATEDIFF( DATE(now()+INTERVAL'7'hour), DATE(audit.create_time+INTERVAL'7'hour))>0\n",
    "                AND DATEDIFF(DATE(now()+INTERVAL'-24' hour+INTERVAL'7'hour), DATE(audit.create_time + interval'2' hour+INTERVAL'7'hour))<DAY(now()+INTERVAL'-24' hour+INTERVAL'7'hour) \n",
    "            )t2\n",
    "            GROUP BY  t2.collector_id\n",
    "                     ,t2.full_name_x\n",
    "                     ,substring_index(full_name_x,\"-\",1)\n",
    "                     ,assign_stage\n",
    "                     ,t2.team_leader_name\n",
    "                     ,group_name\n",
    "                     ,t2.team_name\n",
    "                     ,NOW() \"\"\")\n",
    "    df3.repartition(1).write.mode(\"append\").orc(\"s3://rupiahplus-data-warehouse/etl/banda/report_temp_table/coll_collector_info_detail_dt/\")\n",
    "    df4=spark.sql(\"\"\"\n",
    "            -- 创建增量表，催收人员每日工作情况明细每日更新前一日数据\n",
    "            -- banda_rpt_mid.coll_work_detail_daily\n",
    "            -- `banda-etl-s3`.t_call_center_info数据不全，采用增量表的方式\n",
    "            SELECT  date(call_lg.create_time+interval'7'hour) AS DATE\n",
    "                   ,call_lg.caller_id\n",
    "                   ,assign_stage\n",
    "                   ,admin.full_name_x      AS full_name\n",
    "                   ,COUNT(call_lg.call_id) AS count\n",
    "                   ,'call_count'AS type\n",
    "\n",
    "                   ,now()                  AS insert_time\n",
    "            FROM `banda-etl-s3`.t_call_center_log call_lg\n",
    "            LEFT JOIN\n",
    "            (\n",
    "                SELECT  collector_id\n",
    "                       ,assign_stage\n",
    "                       ,full_name_x\n",
    "                FROM banda_rpt_mid.t_assign_detail_stage_daily\n",
    "                WHERE rn_total_desc=1--取最后一次分案\n",
    "                AND date_format(create_time+interval'7'hour,'yy-MM')=date_format(now()+INTERVAL '-1'day,'yy-MM') --取观测日前一天的当月全量分案\n",
    "                GROUP BY  collector_id\n",
    "                         ,assign_stage\n",
    "                         ,full_name_x\n",
    "            )admin\n",
    "            ON admin.collector_id=call_lg.caller_id\n",
    "            WHERE date(call_lg.create_time+interval'7'hour)=DATE(now()+INTERVAL '-1'day+interval'7'hour)\n",
    "            AND call_lg.caller_id is NOT NULL\n",
    "            AND admin.full_name_x is NOT NULL\n",
    "            GROUP BY  date(call_lg.create_time+interval'7'hour)\n",
    "                     ,call_lg.caller_id\n",
    "                     ,assign_stage\n",
    "                     ,admin.full_name_x\n",
    "\n",
    "            -- 当日log去重量：当日在库案件中标记过log的案件数（每日每个案子仅计算一次）\n",
    "            UNION ALL\n",
    "\n",
    "            SELECT  date(rel.create_time+interval'7'hour) AS DATE\n",
    "                   ,rel.update_id                         AS collector_id\n",
    "                   ,dd.assign_stage\n",
    "                   ,dd.full_name_x\n",
    "                   ,COUNT(distinct rel.loan_id)           AS count\n",
    "                   ,'log_count'AS type\n",
    "\n",
    "                   ,now()                                 AS insert_time\n",
    "            FROM\n",
    "            (\n",
    "                SELECT  rel.loan_id\n",
    "                       ,rel.create_time\n",
    "                       ,update_id\n",
    "                FROM `banda-etl-s3`.t_loan_tag_rel rel\n",
    "                JOIN\n",
    "                (\n",
    "                    SELECT  id\n",
    "                    FROM `banda-etl-s3`.t_tag\n",
    "                    WHERE type='MANUAL_COLLECTION_LOG'\n",
    "                    AND status='ACTIVE' \n",
    "                )tag\n",
    "                ON tag.id=rel.tag_id\n",
    "            ) rel\n",
    "            LEFT JOIN banda_rpt_mid.t_assign_detail_stage_daily dd\n",
    "            ON rel.loan_id=dd.loan_app_id AND rel.update_id=dd.collector_id\n",
    "            WHERE date(rel.create_time+interval'7'hour)=DATE(now()+INTERVAL '-1'day+interval'7'hour)\n",
    "            AND dd.collector_id is not null\n",
    "            GROUP BY  date(rel.create_time+interval'7'hour)\n",
    "                     ,rel.update_id\n",
    "                     ,dd.assign_stage\n",
    "                     ,dd.full_name_x\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- 当天主动还款案件量：当天未下log的paid off案件数\n",
    "            SELECT  date(lg.create_time+interval'7'hour)     AS DATE\n",
    "                   ,assign.collector_id \n",
    "                   ,assign.assign_stage\n",
    "                   ,assign.full_name_x\n",
    "                   ,COUNT(DISTINCT assign.loan_app_id)       AS count\n",
    "                   ,'Initiatively_count'AS type\n",
    "                   ,now() as insert_time\n",
    "            FROM\n",
    "            ( SELECT*\n",
    "                FROM  banda_rpt_mid.t_assign_detail_stage_daily\n",
    "                WHERE rn_total_desc=1 \n",
    "            ) assign\n",
    "            JOIN\n",
    "            ( select*from `banda-etl-s3`.t_loan_app\n",
    "                WHERE product_name='RUPIAHONE'\n",
    "                AND status='PAID_OFF' \n",
    "            ) app\n",
    "            ON assign.loan_app_id=app.id\n",
    "            LEFT JOIN\n",
    "            ( select*from `banda-etl-s3`.t_loan_app_status_log\n",
    "                WHERE new_status='PAID_OFF' \n",
    "            )lg\n",
    "            ON lg.loan_app_id=app.id\n",
    "            LEFT JOIN\n",
    "            (\n",
    "                SELECT  rel2.loan_id\n",
    "                       ,update_id\n",
    "                       ,rel2.create_time AS log_time\n",
    "                FROM `banda-etl-s3`.t_loan_tag_rel rel2\n",
    "                JOIN\n",
    "                (\n",
    "                    SELECT  id\n",
    "                    FROM `banda-etl-s3`.t_tag\n",
    "                    WHERE type='MANUAL_COLLECTION_LOG'\n",
    "                    AND status='ACTIVE' \n",
    "                )tag\n",
    "                ON tag.id=rel2.tag_id\n",
    "            )t1\n",
    "            ON t1.loan_id=assign.loan_app_id AND t1.update_id=assign.collector_id\n",
    "            LEFT JOIN\n",
    "            (\n",
    "                SELECT  rel2.loan_id\n",
    "                       ,update_id\n",
    "                       ,rel2.create_time AS log_time\n",
    "                FROM `banda-etl-s3`.t_loan_tag_rel rel2\n",
    "                JOIN\n",
    "                (\n",
    "                    SELECT  id\n",
    "                    FROM `banda-etl-s3`.t_tag\n",
    "                    WHERE type='MANUAL_COLLECTION_LOG'\n",
    "                    AND status='ACTIVE' \n",
    "                )tag\n",
    "                ON tag.id=rel2.tag_id\n",
    "            )t2\n",
    "            ON t2.loan_id=assign.loan_app_id AND date(t2.log_time+interval'7'hour)=date(lg.create_time+interval'7'hour)\n",
    "            WHERE date(lg.create_time+interval'7'hour)=DATE(now()+INTERVAL '-1'day+interval'7'hour) \n",
    "            AND (t1.loan_id IS NULL OR date(t1.log_time+interval'7'hour)<date(lg.create_time+interval'7'hour)) -- 没有催记标记就结清或者LOG当天之后结清\n",
    "            AND t2.loan_id is null -- 结清当日有催记的剔除（有催记的案件已被计算到当日LOG去重数里面，避免重复计算）\n",
    "            GROUP BY  date(lg.create_time+interval'7'hour)\n",
    "                     ,assign.collector_id\n",
    "                     ,assign.assign_stage\n",
    "                     ,assign.full_name_x\n",
    "    \"\"\")\n",
    "    df4.repartition(1).write.mode(\"append\").orc(\"s3://rupiahplus-data-warehouse/etl/banda/report_temp_table/coll_work_detail_daily/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8cbcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978e8df9d3694c92ad83404dda0d894e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+------------+-----+-------------------+--------------------+\n",
      "|      DATE|collector_id|         full_name_x|assign_stage|count|       unpaid_amoun|         insert_time|\n",
      "+----------+------------+--------------------+------------+-----+-------------------+--------------------+\n",
      "|2021-08-19|      102213|Octavianus Sukman...|          Q0|  153| 288709999.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102428|     Evi Lestasri-Q3|          Q3|  380| 573164000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102375|Christopher Louis...|          Q2|  172| 271515000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102167|Wiwin Wijayanto - Q2|          Q2|  171| 269565200.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102411|Wiwit Aulia Suwar...|          Q0|  153| 291488000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102042|Adhitya Syahputra-Q3|          Q3|  380| 565870600.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102435|    Ayu Pebrianti-Q4|          Q4| 2118|2762447770.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102096|  Achmad widodo - Q2|          Q2|  172| 280597160.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102285|          SSS-Q4-004|          Q4| 2120|2806568900.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102159|  Irma Herawati - Q2|          Q2|  171| 270524000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      101995|Moudhyahtuzahra - Q0|          Q0|  153| 273242000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102147|collection-robot-...|          QZ|  234| 474218400.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102426|   Lian Kristanto-Q3|          Q3|  381| 574879000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102092|      Putri Sinta-Q3|          Q3|  381| 573023588.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102364| Zulkarnain - Q1 old|      Q1_OLD|  107| 227923800.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102376| Puji Handayani - Q2|          Q2|  172| 266256200.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102352|Yudi Gotama - Q1 new|      Q1_NEW|   95|  86542000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      101526|  Syifa Fauziah - Q0|          Q0|  153| 284046000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      101938|         Gustiani-Q2|          Q2|  172| 268908000.00000000|2021-08-19 10:12:...|\n",
      "|2021-08-19|      102365|Tiara Brigita Pas...|          Q2|  167| 262290700.00000000|2021-08-19 10:12:...|\n",
      "+----------+------------+--------------------+------------+-----+-------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "-- 新建表：banda_rpt_mid.coll_outsouring_detail_daily\n",
    "-- 增量更新，每日新增数据进去，之前数据保留\n",
    "SELECT  date(now()+interval '-1'day+ INTERVAL '7' hour) AS DATE\n",
    "       ,t4.collector_id\n",
    "       ,t4.full_name\n",
    "       ,t4.overdue\n",
    "       ,t4.gp_name\n",
    "       ,COUNT(DISTINCT t4.loan_app_id) AS count\n",
    "       ,SUM(t4.unpaid_amount)          AS unpaid_amount\n",
    "       ,SUM(t4.unpaid_total)           AS unpaid_total\n",
    "       ,now() as insert_time\n",
    "FROM\n",
    "(\n",
    "\tSELECT  t3.collector_id\n",
    "\t       ,t3.full_name\n",
    "\t       ,t3.overdue\n",
    "\t       ,t3.gp_name\n",
    "\t       ,t3.loan_app_id\n",
    "\t       ,t3.create_time\n",
    "\t       ,t3.amount\n",
    "\t       ,t3.clear_amount\n",
    "\t       ,t3.clear_principal\n",
    "\t       ,CASE WHEN t3.clear_principal IS NULL THEN t3.amount  ELSE t3.amount-t3.clear_principal END AS unpaid_amount\n",
    "\t       ,CASE WHEN t3.clear_total IS NULL THEN t3.total_accr  ELSE t3.total_accr-t3.clear_total END AS unpaid_total\n",
    "\t       ,row_number()OVER (PARTITION BY t3.loan_app_id,t3.gp_name ORDER BY t3.create_time ASC )as num2--一个组第一次分案记录\n",
    "\tFROM\n",
    "\t(\n",
    "\t\tSELECT  t2.collector_id\n",
    "\t\t       ,t2.full_name\n",
    "\t\t       ,t2.overdue\n",
    "\t\t       ,t2.gp_name\n",
    "\t\t       ,t2.loan_app_id\n",
    "\t\t       ,t2.amount\n",
    "\t\t       ,t2.total_accr\n",
    "\t\t       ,t2.create_time\n",
    "\t\t       ,SUM(deposit.cleared_amount)                                         AS clear_amount\n",
    "\t\t       ,SUM(clear.principal)                                                AS clear_principal\n",
    "\t\t       ,SUM(clear.principal+clear.interest+clear.penalty+clear.default_fee) AS clear_total\n",
    "\t\tFROM\n",
    "\t\t(\n",
    "\t\t\tSELECT  t1.loan_app_id\n",
    "\t\t\t       ,t1.collector_id\n",
    "\t\t\t       ,t1.full_name\n",
    "\t\t\t       ,t1.gp_name\n",
    "\t\t\t       ,t1.overdue\n",
    "\t\t\t       ,t1.amount\n",
    "\t\t\t       ,t1.total_accr\n",
    "\t\t\t       ,t1.create_time\n",
    "\t\t\t       ,t1.id\n",
    "\t\t\t       ,t1.erase_amount\n",
    "\t\t\t       ,row_number()OVER (PARTITION BY t1.loan_app_id,t1.overdue ORDER BY t1.create_time DESC )AS num--一个逾期阶段最后一次分案记录\n",
    "\t\t\tFROM\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT  audit.admin_id\n",
    "\t\t\t\t       ,audit.collector_id\n",
    "\t\t\t\t       ,ad.full_name_x                                                                                                                 AS full_name\n",
    "\t\t\t\t       ,audit.loan_app_id\n",
    "\t\t\t\t       ,audit.create_time\n",
    "\t\t\t\t       ,app.amount\n",
    "\t\t\t\t       ,lpay.principal_accr+lpay.interest_accr+lpay.default_accr+lpay.default_fee_accr                                                 AS total_accr\n",
    "\t\t\t\t       ,lpay.due_date\n",
    "\t\t\t\t       ,lpay.id\n",
    "\t\t\t\t       ,lpay.erase_amount\n",
    "\t\t\t\t       ,substr(depart.name,-2)                                                                                                         AS gp_name\n",
    "\t\t\t\t       ,CASE WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>179 THEN 180\n",
    "\t\t\t\t             WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>89 THEN 90\n",
    "\t\t\t\t             WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>60 THEN 61\n",
    "\t\t\t\t             WHEN datediff(date(audit.create_time+interval'7'hour),date(lpay.due_date+interval'7'hour))>31 THEN 32  ELSE 31 END AS overdue\n",
    "\t\t\t\tFROM banda_rpt_mid.t_assign_detail_stage_daily audit\n",
    "\t\t\t\tLEFT JOIN `banda-etl-s3`.t_admin ad\n",
    "\t\t\t\tON ad.id=audit.collector_id\n",
    "\t\t\t\tLEFT JOIN `banda-etl-s3`.t_admin_group ad_group\n",
    "\t\t\t\tON ad_group.admin_id=audit.collector_id AND ad_group.status='ACTIVE'\n",
    "\t\t\t\tLEFT JOIN `banda-etl-s3`.t_department_group depart\n",
    "\t\t\t\tON depart.id=ad_group.group_id AND depart.status='ACTIVE'\n",
    "\t\t\t\tLEFT JOIN `banda-etl-s3`.t_loan_app app\n",
    "\t\t\t\tON app.id=audit.loan_app_id\n",
    "\t\t\t\tLEFT JOIN `banda-etl-s3`.t_lpay lpay\n",
    "\t\t\t\tON lpay.loan_app_id=audit.loan_app_id\n",
    "\t\t\t\tWHERE datediff(date(now()+ INTERVAL '7' hour), date(audit.create_time+ INTERVAL '7' hour) )>0\n",
    "\t\t\t\tAND datediff(date(now()+INTERVAL'-24' hour+ INTERVAL '7' hour), date(audit.create_time + INTERVAL '2' hour+ INTERVAL '7' hour))<day(now()+INTERVAL'-24'hour+ INTERVAL '7' hour)\n",
    "\t\t\t\tAND datediff( date(audit.create_time + INTERVAL '2' hour+ INTERVAL '7' hour), date(lpay.due_date+ INTERVAL '7' hour))>30\n",
    "\t\t\t\tAND depart.name is NOT NULL\n",
    "\t\t\t)t1\n",
    "\t\t)t2\n",
    "\t\tLEFT JOIN `banda-etl-s3`.t_lpay_deposit deposit\n",
    "\t\tON deposit.lpay_id=t2.id AND deposit.status='CLEARED' AND deposit.create_time<t2.create_time \n",
    "\t\tAND ( deposit.deposit_method !='DIRECT_TRANSFER' OR (deposit.deposit_method ='DIRECT_TRANSFER' AND deposit.cleared_amount !=ceil(t2.erase_amount)))\n",
    "\t\tLEFT JOIN `banda-etl-s3`.t_reduce reduce\n",
    "\t\tON reduce.deposit_id =deposit.id AND reduce.reduce_status='SUCCEED'\n",
    "\t\tLEFT JOIN `banda-etl-s3`.t_clear_detail_log clear\n",
    "\t\tON clear.deposit_id=deposit.id\n",
    "\t\tWHERE t2.num=1\n",
    "\t\tAND (reduce.reduce_type IS NULL OR reduce.reduce_type NOT IN ('DELAY_CALLBACK', 'NONE_CALLBACK_REDUCE', 'COLLECTION_REDUCE'))\n",
    "\t\tGROUP BY  t2.collector_id\n",
    "\t\t         ,t2.full_name\n",
    "\t\t         ,t2.overdue\n",
    "\t\t         ,t2.gp_name\n",
    "\t\t         ,t2.loan_app_id\n",
    "\t\t         ,t2.amount\n",
    "\t\t         ,t2.total_accr\n",
    "\t\t         ,t2.create_time\n",
    "\t)t3\n",
    ")t4\n",
    "WHERE t4.num2=1\n",
    "GROUP BY  date(now()+interval '-1'day+ INTERVAL '7' hour)\n",
    "         ,t4.collector_id\n",
    "         ,t4.full_name\n",
    "         ,t4.overdue\n",
    "         ,t4.gp_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a1a6c",
   "metadata": {},
   "source": [
    "########补充历史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18f4fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389e2c8906414e1eb97d18ba63e8cae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=spark.sql(\"\"\"\n",
    "\n",
    "    select * from zhusu.temp_current_case_0801  union \n",
    "    select * from zhusu.temp_current_case_0802 union\n",
    "    select * from zhusu.temp_current_case_0803 union\n",
    "    select * from zhusu.temp_current_case_0804  union\n",
    "    select * from zhusu.temp_current_case_0805 union\n",
    "    select * from zhusu.temp_current_case_0806 union\n",
    "    select * from zhusu.temp_current_case_0807 union\n",
    "    select * from zhusu.temp_current_case_0808 union \n",
    "    select * from zhusu.temp_current_case_0809  union\n",
    "    select * from  zhusu.temp_current_case_0810 union\n",
    "    select * from zhusu.temp_current_case_0811 union\n",
    "    select * from zhusu.temp_current_case_0812 union\n",
    "    select * from zhusu.temp_current_case_0813 union\n",
    "    select * from zhusu.temp_current_case_0814 union\n",
    "    select * from zhusu.temp_current_case_0815 \n",
    "\n",
    "\"\"\")\n",
    "df.repartition(1).write.mode(\"append\").orc(\"s3://rupiahplus-data-warehouse/etl/banda/report_temp_table/t_case_in_collection_increment/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f8dfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad02affb5af342bdba96c50b9ba01265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    df1=spark.sql(\"\"\"\n",
    "            -- 创建日分区表 banda_rpt_mid.coll_collector_info_detail_dt\n",
    "            -- 每日数据存为一个分区保留记录\n",
    "            -- partition by dt\n",
    "\n",
    "            SELECT  t2.collector_id\n",
    "                   ,t2.full_name_x\n",
    "                   ,substring_index(full_name_x,\"-\",1) AS collector_name\n",
    "                   ,assign_stage\n",
    "                   ,t2.team_leader_name\n",
    "                   ,group_name\n",
    "                   ,t2.team_name\n",
    "                   ,NOW() as insert_time,\n",
    "                   date(now()) as date_time\n",
    "            FROM\n",
    "            (\n",
    "                SELECT  audit.*\n",
    "                       ,ad.team_leader_id\n",
    "                       ,depart.description AS team_name\n",
    "                       ,depart.name        AS group_name\n",
    "                       ,depart2.description\n",
    "                       ,ad2.full_name_x    AS team_leader_name\n",
    "                FROM\n",
    "                ( select*from banda_rpt_mid.t_assign_detail_stage_daily\n",
    "                    WHERE rn_ingroup_desc=1 \n",
    "                ) audit\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin ad\n",
    "                ON ad.id=audit.collector_id\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin_group ad_group\n",
    "                ON ad_group.admin_id=audit.collector_id AND ad_group.status= 'ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_department_group depart\n",
    "                ON depart.id=ad_group.group_id AND depart.status='ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_department_group depart2\n",
    "                ON depart2.id=depart.parent_id AND depart2.status='ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin_group ad_group2\n",
    "                ON ad_group2.group_id=depart2.id AND ad_group2.status='ACTIVE'\n",
    "                LEFT JOIN `banda-etl-s3`.t_admin ad2\n",
    "                ON ad2.id=ad_group2.admin_id\n",
    "                WHERE depart.name IS NOT NULL\n",
    "                AND DATEDIFF( DATE(now()+INTERVAL'7'hour), DATE(audit.create_time+INTERVAL'7'hour))>0\n",
    "                AND DATEDIFF(DATE(now()+INTERVAL'-24' hour+INTERVAL'7'hour), DATE(audit.create_time + interval'2' hour+INTERVAL'7'hour))<DAY(now()+INTERVAL'-24' hour+INTERVAL'7'hour) \n",
    "            )t2\n",
    "            GROUP BY  t2.collector_id\n",
    "                     ,t2.full_name_x\n",
    "                     ,substring_index(full_name_x,\"-\",1)\n",
    "                     ,assign_stage\n",
    "                     ,t2.team_leader_name\n",
    "                     ,group_name\n",
    "                     ,t2.team_name\n",
    "                     ,NOW() \"\"\")\n",
    "    df1.repartition(1).write.mode(\"append\").orc(\"s3://rupiahplus-data-warehouse/etl/banda/report_temp_table/coll_collector_info_detail_dt11/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
